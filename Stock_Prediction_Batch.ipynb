{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZlLIu7uE5ma"
   },
   "source": [
    "# Stock Prediction\n",
    "### Ignacio Fernández Adrados\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%pip install pandas\\n%pip install scikit-learn\\n%pip install matplotlib\\n%pip install numpy\\n%pip install keras\\n%pip install tensorflow\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install keras\n",
    "%pip install tensorflow\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "seE3JuEGE5mh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # type: ignore\n",
    "\n",
    "def getStockDataFrame (stock, years):\n",
    "    STOCK = stock\n",
    "    YEARS = years\n",
    "\n",
    "    file = None\n",
    "    for year in YEARS:\n",
    "        FILE='Datasets/Stock-'+STOCK+'-'+year+'.csv'\n",
    "        ds=pd.read_csv(FILE, sep=',')\n",
    "        file = pd.concat([file,ds])\n",
    "    file = file.sort_values(by='timestamp', ascending=True)\n",
    "    return file\n",
    "#getStockDataFrame('AAPL', ['2022','2023'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX9Mv-nZFlXk",
    "outputId": "2a025661-a286-4991-9260-66628ec2a250"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def groupStocks(dataset, n, datefilter):\n",
    "\n",
    "    N=n     #Minutos agrupados\n",
    "    DATEFILTER=datefilter #Filtro de fecha\n",
    "    file = dataset\n",
    "    \n",
    "    df = file[file['timestamp'].str.startswith(DATEFILTER)]\n",
    "    df=pd.DataFrame(df)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    dfgroup = pd.DataFrame(df.groupby(pd.Grouper(key='timestamp', freq=N)).first()['open'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).last()['close'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).min()['low'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).max()['high'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).sum()['volume'])\n",
    "    #dfgroup = dfgroup[:-1].reset_index(drop=True)\n",
    "    dfgroup = pd.DataFrame(pd.to_datetime(dfgroup.index[:])).join(dfgroup.reset_index(drop=True))\n",
    "    dfgroup = dfgroup.dropna().reset_index(drop=True)\n",
    "    return dfgroup\n",
    "#xxx = groupStocks(getStockDataFrame('AAPL', ['2022']), '1D', '')\n",
    "#xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "z2bs-Qemi12t",
    "outputId": "161bc113-e1f6-4b25-d8d9-b56f9f078f66"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_rsi(close, lookback):\n",
    "    ret = close.diff()\n",
    "    up = []\n",
    "    down = []\n",
    "    for i in range(len(ret)):\n",
    "        if ret[i] < 0:\n",
    "            up.append(0)\n",
    "            down.append(ret[i])\n",
    "        else:\n",
    "            up.append(ret[i])\n",
    "            down.append(0)\n",
    "    up_series = pd.Series(up)\n",
    "    down_series = pd.Series(down).abs()\n",
    "    up_ewm = up_series.ewm(com = lookback - 1, adjust = False).mean()\n",
    "    down_ewm = down_series.ewm(com = lookback - 1, adjust = False).mean()\n",
    "    rs = up_ewm/down_ewm\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    rsi_df = pd.DataFrame(rsi).rename(columns = {0:'rsi'}).set_index(close.index)\n",
    "    rsi_df = rsi_df.dropna()\n",
    "    return rsi_df[3:]\n",
    "\n",
    "def getIndicators(dataset):\n",
    "    \n",
    "    dfgroup = dataset\n",
    "\n",
    "    dfgroup['EMA7']= dfgroup['close'].ewm(span=7, adjust=False).mean()\n",
    "    dfgroup['MACD']= dfgroup['close'].ewm(span=12, adjust=False).mean()- dfgroup['close'].ewm(span=26, adjust=False).mean()\n",
    "    dfgroup['SignalMACD'] = dfgroup['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    dfgroup['RSI'] = get_rsi(dfgroup['close'], 14)\n",
    "    dfgroup = dfgroup.dropna()\n",
    "    dfgroup = dfgroup.reset_index(drop=True)\n",
    "    return dfgroup\n",
    "\n",
    "#getIndicators(xxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadiendo sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TBisHNoeE5mo",
    "outputId": "314904d0-9fde-4c6f-96fd-1eaaff6387dc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize(dataset):\n",
    "    #Normalise data into (0,1) range\n",
    "    normData=dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    #normData[['open']] = scaler.fit_transform(normData[['open']])\n",
    "    normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']] = \\\n",
    "        scaler.fit_transform(normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']])\n",
    "    return normData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "hY9NX9AeE5mp",
    "outputId": "6d446865-54a0-4bb4-b540-46dc88bb3e9d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotDataset(dataset):\n",
    "\n",
    "    normData = dataset\n",
    "    \n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Dataset 'Close' data \")\n",
    "    plt.plot(normData['close'],color='black')\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] == -1,normData['close'], None), color=\"red\", marker=\"v\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] ==  1,normData['close'], None), color=\"blue\", marker=\"^\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W41DlLEoE5mq"
   },
   "source": [
    "### Split the values in train and test\n",
    "\n",
    "So, we took only 25% of the data as training samples and set aside the rest of the data for testing.\n",
    "\n",
    "Looking at the time-series plot, we think **it is not easy for a standard model to come up with correct trend predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "es2T4CuCE5mr",
    "outputId": "7e2cbeb1-c779-415b-ba2d-295f95a7a854"
   },
   "outputs": [],
   "source": [
    "def splitData(dataset, split, step):\n",
    "\n",
    "    S=split\n",
    "    step = step\n",
    "    normData = dataset\n",
    "\n",
    "    split = int(len(normData) * S)\n",
    "    #values = normData.values\n",
    "    #print(values)\n",
    "    train = normData[:split]#.drop(['buysell'],axis=1)\n",
    "    test = pd.concat([train.tail(step),normData[split:]]).reset_index(drop=True)\n",
    "\n",
    "    #print(\"Train data length:\", train.shape)\n",
    "    #print(\"Test data length:\", test.shape)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "yq8Pr6juE5ms",
    "outputId": "0870926c-f065-418c-e5bd-07c141e27bce"
   },
   "outputs": [],
   "source": [
    "def plotSplitDataset(dataset, split):\n",
    "    \n",
    "    normData = dataset\n",
    "    split = int(len(normData) * split)\n",
    "\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Dataset 'Close' data split\")\n",
    "    plt.plot(normData.index.values,normData['close'],c='black')\n",
    "    plt.axvline(normData.index[split], c=\"r\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] == -1,normData['close'], None), color=\"red\",  marker=\"v\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] ==  1,normData['close'], None), color=\"blue\", marker=\"^\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4No4lvOSE5mu"
   },
   "source": [
    "### Converting to a multi-dimensional array\n",
    "Next, we'll convert test and train data into the matrix with step value as it has shown above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8J-93wpyE5mu",
    "outputId": "1deefe1b-450d-4a34-98c4-c526e71c4688"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convertToMatrix(data, step):\n",
    "    X, Y =[], []\n",
    "    for i in range(len(data)-step):\n",
    "        d=i+step\n",
    "        #print(i, d, data[i:d)\n",
    "        X.append(data[i:d])\n",
    "        Y.append(data[d,1])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def dataset2Matrix(train, test, step):\n",
    "    trainX,trainY =convertToMatrix(train.to_numpy(),step)\n",
    "    testX,testY =convertToMatrix(test.to_numpy(),step)\n",
    "    #print(trainY)\n",
    "    #print(\"Training data shape:\", trainX.shape,', ',trainY.shape)\n",
    "    #print(\"Test data shape:\", testX.shape,', ',testY.shape)\n",
    "    return trainX, trainY, testX, testY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfLqFjJxE5mw"
   },
   "source": [
    "### Keras model with `SimpleRNN` layer\n",
    "\n",
    "- 256 neurons in the RNN layer\n",
    "- 32 denurons in the densely connected layer\n",
    "- a single neuron for the output layer\n",
    "- ReLu activation\n",
    "- learning rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "4BjedTvlE5mw",
    "outputId": "a224d1e0-e032-4e1b-d276-12049d88cebb"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, LSTM, Dropout # type: ignore\n",
    "\n",
    "def createModel(type, units, trainX, step):\n",
    "    UNITS = units #num_units: Number of units of a the simple RNN layer\n",
    "    DENSEUNITS = 32 #Number of neurons in the dense layer followed by the RNN layer\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input((step, trainX.shape[2])))\n",
    "    if type==\"LSTM\":\n",
    "        model.add(LSTM(units=UNITS, activation=\"tanh\",return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=UNITS//2, activation=\"tanh\"))\n",
    "        model.add(Dropout(0.2))      \n",
    "    elif type == \"RNN\":\n",
    "        model.add(SimpleRNN(units=UNITS, activation=\"relu\",return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(SimpleRNN(units=UNITS//2, activation=\"relu\"))\n",
    "        model.add(Dropout(0.2))     \n",
    "    model.add(Dense(DENSEUNITS, activation=\"tanh\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mse'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg4jkMzRE5mz"
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyGK1fyFE5mz",
    "outputId": "9a183877-c6d8-4587-802c-12e4f8c4e138"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback # type: ignore\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        #if (epoch+1) % 10 == 0 and epoch>0:\n",
    "            print(\"Epoch number {} done\".format(epoch+1))\n",
    "\n",
    "def trainModel(model, batch, epochs, trainX, trainY):\n",
    "    batch_size=batch\n",
    "    num_epochs = epochs\n",
    "\n",
    "    model.fit(trainX,trainY,\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=None,verbose=0\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8u8PJjdE5m0"
   },
   "source": [
    "### Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "UoYGhk7EE5m0",
    "outputId": "4f2b1a4c-31cc-4eab-e5d0-f86b9c6489bd"
   },
   "outputs": [],
   "source": [
    "def plotLosss(model):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.title(\"RMSE loss over epochs\",fontsize=16)\n",
    "    plt.plot(np.sqrt(model.history.history['loss']),c='k',lw=2)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Epochs\",fontsize=14)\n",
    "    plt.ylabel(\"Root-mean-squared error\",fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d_0G0OpE5m1"
   },
   "source": [
    "### Predictions\n",
    "Note that the model was fitted only with the `trainX` and `trainY` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-cH3SZuE5m2",
    "outputId": "56231db1-6f88-4b7e-8352-aaa6520a042e"
   },
   "outputs": [],
   "source": [
    "def predict(model, trainX, testX):\n",
    "    trainPredict = model.predict(trainX, verbose=0)\n",
    "    testPredict= model.predict(testX, verbose=0)\n",
    " \n",
    "    predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "    #print(trainPredict.shape)\n",
    "    #print(testPredict.shape)\n",
    "\n",
    "    return trainPredict, testPredict, predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enWdLcInE5m3"
   },
   "source": [
    "### Comparing it with the ground truth (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "MoxCTnZqE5m3",
    "outputId": "32af9acf-1724-414b-e43f-8f5b0ce90759"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plotCompare(normData, testPredict, split):\n",
    "\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "    #index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black', label='Ground Truth')\n",
    "    plt.plot(testPredict[OFFSET:],color='blue', label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDecision(test, testPredict, step, profit):\n",
    "\n",
    "    PROFIT = profit\n",
    "\n",
    "    decision=test['close'].iloc[step:]\n",
    "    decision = decision.diff()\n",
    "    decision = decision.dropna()\n",
    "    decision = np.where(abs(decision)<PROFIT,0,np.sign(decision).astype('int'))\n",
    "    decision = pd.DataFrame(data={'buysell':decision})#.drop(0).reset_index(drop=True)\n",
    "\n",
    "    predictedDecision = pd.DataFrame(data={'buysellPredicted':testPredict[:,0]})\n",
    "    predictedDecision = predictedDecision.diff()\n",
    "    predictedDecision = predictedDecision.dropna()#.reset_index(drop=True)\n",
    "    predictedDecision = np.where(abs(predictedDecision)<PROFIT,0,np.sign(predictedDecision).astype('int'))\n",
    "    predictedDecision = pd.DataFrame(data={'buysellPredicted':predictedDecision[:,0]})\n",
    "\n",
    "    decision = decision.join(predictedDecision)\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "Xg5ICE2T8JSa",
    "outputId": "5c4d5a98-1cf4-4899-ca4a-c1cd85f97b4e"
   },
   "outputs": [],
   "source": [
    "def plotResult(normData, testPredict, split, profit, decision):\n",
    "\n",
    "    PROFIT=profit\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "\n",
    "    \n",
    "\n",
    "    index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black')\n",
    "    plt.plot(testPredict[OFFSET:],color='blue')\n",
    "\n",
    "    x = decision.iloc[OFFSET:].reset_index(drop=True).index\n",
    "    y = normData['close'].iloc[len(normData)-len(decision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "\n",
    "    plt.scatter(x, np.where(decision['buysell'].iloc[OFFSET:] == -1,y, None), color=\"red\",  marker=\"v\", label='Ground Truth Sell')\n",
    "    plt.scatter(x, np.where(decision['buysell'].iloc[OFFSET:] ==  1,y, None), color=\"blue\", marker=\"^\", label='Ground Truth Buy')\n",
    "\n",
    "    plt.scatter(x, np.where(decision['buysellPredicted'].iloc[OFFSET:] == -1,y-0.015, None), color=\"orange\",  marker=\"v\", label='Prediction Sell')\n",
    "    plt.scatter(x, np.where(decision['buysellPredicted'].iloc[OFFSET:] ==  1,y+0.015, None), color=\"green\",  marker=\"^\", label='Prediction Buy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "K8VIy1uYFhdb",
    "outputId": "66fae12b-291b-4cce-a052-b57ee39fd236"
   },
   "outputs": [],
   "source": [
    "def plotProfit(normData, split, decision):\n",
    "\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "    index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black')\n",
    "    #plt.plot(testPredict[OFFSET:],color='blue')\n",
    "\n",
    "    x = decision.iloc[OFFSET:].reset_index(drop=True).index\n",
    "    y = normData['close'].iloc[len(normData)-len(decision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "\n",
    "    plt.scatter(x, np.where((decision['buysell'].iloc[OFFSET:] !=  decision['buysellPredicted'].iloc[OFFSET:]) & (decision['buysellPredicted'].iloc[OFFSET:] != 0),y, None), color=\"red\", label='Ground Truth Buy')\n",
    "    plt.scatter(x, np.where((decision['buysell'].iloc[OFFSET:] == decision['buysellPredicted'].iloc[OFFSET:]) & (decision['buysell'].iloc[OFFSET:] != 0),y, None), color=\"green\",  label='Ground Truth Sell')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yN3Hp3azZi3c",
    "outputId": "1a0bbe4e-1fc8-413a-cd3c-aa7b277e5c31"
   },
   "outputs": [],
   "source": [
    "def calculateProfit(normData, decision):\n",
    "\n",
    "    OFFSET=0\n",
    "    y = normData['close'].iloc[len(normData)-len(decision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "    \n",
    "    #print(\"Predicciones no coincidentes con el conjunto de pruebas: \", \\\n",
    "    nocoincide =np.count_nonzero(np.where((decision['buysell'].iloc[OFFSET:] !=  decision['buysellPredicted'].iloc[OFFSET:]) \\\n",
    "          & (decision['buysellPredicted'].iloc[OFFSET:] != 0),y, None))#)\n",
    "    #print(\"Predicciones coincidentes con el conjunto de pruebas: \", \\\n",
    "    coincide=np.count_nonzero(np.where((decision['buysell'].iloc[OFFSET:] == decision['buysellPredicted'].iloc[OFFSET:]) \\\n",
    "          & (decision['buysell'].iloc[OFFSET:] != 0),y, None))#)\n",
    "    return coincide, nocoincide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################  \n",
    "data = getStockDataFrame('AAPL', ['2023'])\n",
    "groupedData = groupStocks(data,'1min', '').drop(['timestamp'],axis=1)\n",
    "indicatorData = getIndicators(groupedData)\n",
    "#######################################################################################  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>relevance</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5383</th>\n",
       "      <td>2023-09-30 12:00:00</td>\n",
       "      <td>0.910514</td>\n",
       "      <td>0.252579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>2023-09-30 12:15:00</td>\n",
       "      <td>0.077593</td>\n",
       "      <td>0.250283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5381</th>\n",
       "      <td>2023-09-30 13:30:55</td>\n",
       "      <td>0.125134</td>\n",
       "      <td>0.144446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>2023-09-30 16:00:00</td>\n",
       "      <td>0.034063</td>\n",
       "      <td>0.047475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>2023-09-30 16:44:07</td>\n",
       "      <td>0.291644</td>\n",
       "      <td>0.181279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date  relevance  sentiment\n",
       "5383 2023-09-30 12:00:00   0.910514   0.252579\n",
       "5382 2023-09-30 12:15:00   0.077593   0.250283\n",
       "5381 2023-09-30 13:30:55   0.125134   0.144446\n",
       "5380 2023-09-30 16:00:00   0.034063   0.047475\n",
       "5379 2023-09-30 16:44:07   0.291644   0.181279"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################################################                            \n",
    "STOCK = 'AAPL'\n",
    "YEARS = ['2023']\n",
    "file = None\n",
    "for year in YEARS:\n",
    "    FILE='Datasets/News-'+STOCK+'-'+year+'.csv'\n",
    "    ds=pd.read_csv(FILE, sep=',')\n",
    "    file = pd.concat([file,ds])\n",
    "file = file.sort_values(by='date', ascending=True)\n",
    "\n",
    "file['date'] = pd.to_datetime(file['date'], format='%Y%m%dT%H%M%S')\n",
    "file = file.drop(['title','summary','ticker'], axis=1)\n",
    "file.tail()\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>relevance</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16122</th>\n",
       "      <td>2023-01-03 04:00:00</td>\n",
       "      <td>128.9280</td>\n",
       "      <td>129.6405</td>\n",
       "      <td>128.9280</td>\n",
       "      <td>129.6405</td>\n",
       "      <td>5381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16121</th>\n",
       "      <td>2023-01-03 04:01:00</td>\n",
       "      <td>129.5119</td>\n",
       "      <td>129.8088</td>\n",
       "      <td>129.5119</td>\n",
       "      <td>129.7395</td>\n",
       "      <td>6072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16120</th>\n",
       "      <td>2023-01-03 04:02:00</td>\n",
       "      <td>129.8187</td>\n",
       "      <td>129.8780</td>\n",
       "      <td>129.8088</td>\n",
       "      <td>129.8088</td>\n",
       "      <td>1053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16119</th>\n",
       "      <td>2023-01-03 04:03:00</td>\n",
       "      <td>129.8286</td>\n",
       "      <td>129.9275</td>\n",
       "      <td>129.8286</td>\n",
       "      <td>129.9176</td>\n",
       "      <td>1754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16118</th>\n",
       "      <td>2023-01-03 04:04:00</td>\n",
       "      <td>129.9176</td>\n",
       "      <td>130.0958</td>\n",
       "      <td>129.9176</td>\n",
       "      <td>130.0958</td>\n",
       "      <td>3766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201428</th>\n",
       "      <td>2023-12-29 19:55:00</td>\n",
       "      <td>191.2934</td>\n",
       "      <td>191.3033</td>\n",
       "      <td>191.2834</td>\n",
       "      <td>191.2834</td>\n",
       "      <td>717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201427</th>\n",
       "      <td>2023-12-29 19:56:00</td>\n",
       "      <td>191.2934</td>\n",
       "      <td>191.3033</td>\n",
       "      <td>191.2834</td>\n",
       "      <td>191.2934</td>\n",
       "      <td>532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201426</th>\n",
       "      <td>2023-12-29 19:57:00</td>\n",
       "      <td>191.2934</td>\n",
       "      <td>191.3033</td>\n",
       "      <td>191.2834</td>\n",
       "      <td>191.2834</td>\n",
       "      <td>662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201425</th>\n",
       "      <td>2023-12-29 19:58:00</td>\n",
       "      <td>191.2834</td>\n",
       "      <td>191.2834</td>\n",
       "      <td>191.1640</td>\n",
       "      <td>191.2237</td>\n",
       "      <td>2154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201424</th>\n",
       "      <td>2023-12-29 19:59:00</td>\n",
       "      <td>191.2635</td>\n",
       "      <td>191.2735</td>\n",
       "      <td>191.2138</td>\n",
       "      <td>191.2139</td>\n",
       "      <td>2147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220495 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp      open      high       low     close  volume  \\\n",
       "16122  2023-01-03 04:00:00  128.9280  129.6405  128.9280  129.6405    5381   \n",
       "16121  2023-01-03 04:01:00  129.5119  129.8088  129.5119  129.7395    6072   \n",
       "16120  2023-01-03 04:02:00  129.8187  129.8780  129.8088  129.8088    1053   \n",
       "16119  2023-01-03 04:03:00  129.8286  129.9275  129.8286  129.9176    1754   \n",
       "16118  2023-01-03 04:04:00  129.9176  130.0958  129.9176  130.0958    3766   \n",
       "...                    ...       ...       ...       ...       ...     ...   \n",
       "201428 2023-12-29 19:55:00  191.2934  191.3033  191.2834  191.2834     717   \n",
       "201427 2023-12-29 19:56:00  191.2934  191.3033  191.2834  191.2934     532   \n",
       "201426 2023-12-29 19:57:00  191.2934  191.3033  191.2834  191.2834     662   \n",
       "201425 2023-12-29 19:58:00  191.2834  191.2834  191.1640  191.2237    2154   \n",
       "201424 2023-12-29 19:59:00  191.2635  191.2735  191.2138  191.2139    2147   \n",
       "\n",
       "        relevance  sentiment  \n",
       "16122         NaN        NaN  \n",
       "16121         NaN        NaN  \n",
       "16120         NaN        NaN  \n",
       "16119         NaN        NaN  \n",
       "16118         NaN        NaN  \n",
       "...           ...        ...  \n",
       "201428        NaN        NaN  \n",
       "201427        NaN        NaN  \n",
       "201426        NaN        NaN  \n",
       "201425        NaN        NaN  \n",
       "201424        NaN        NaN  \n",
       "\n",
       "[220495 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################################################  \n",
    "N=\"1min\"\n",
    "\n",
    "dfgroup = pd.DataFrame(file.groupby(pd.Grouper(key='date', freq=N)).last()['relevance'])\n",
    "dfgroup = dfgroup.join(file.groupby(pd.Grouper(key='date', freq=N)).last()['sentiment'])\n",
    "dfgroup = pd.DataFrame(pd.to_datetime(dfgroup.index[:])).join(dfgroup.reset_index(drop=True))\n",
    "dfgroup = dfgroup.fillna(0)\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "#print(data)\n",
    "#print(dfgroup)\n",
    "res = data.join(dfgroup.set_index(\"date\"), on='timestamp')\n",
    "res\n",
    "\n",
    "#######################################################################################  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTest(split, stock, dates, profitMult, intervals, algorithms, steps, units, batchs, profits, epochs):\n",
    "    df = None\n",
    "    i=0\n",
    "    for interval in intervals:\n",
    "        for algorithm in algorithms:\n",
    "            for step in steps:\n",
    "                for unit in units:\n",
    "                    for batch in batchs:\n",
    "\n",
    "                        for epoch in epochs:\n",
    "                            #print('Calculating iteration:', i, ':', 'interval:', str(interval) + \",\",\n",
    "                            #    'algorithm:', algorithm + \",\", 'step:', str(step) + \",\", 'unit:', str(unit), 'batch:', str(batch) + \",\",\n",
    "                            #    'profit:', str(profit*profitMult) + \",\", 'epoch:', str(epoch))\n",
    "                            i += 1\n",
    "                            data = getStockDataFrame(stock, dates )\n",
    "                            groupedData = groupStocks(data,interval, '').drop(['timestamp'],axis=1)\n",
    "                            indicatorData = getIndicators(groupedData)\n",
    "\n",
    "                            finalData = normalize(indicatorData)\n",
    "                            #plotDataset(finalData)\n",
    "                            train, test = splitData(finalData, split, step)\n",
    "                            #plotSplitDataset(s4, split)\n",
    "                            trainX, trainY, testX, testY = dataset2Matrix(train, test, step)\n",
    "                            model = createModel(algorithm, unit,trainX, step)\n",
    "                            #model.summary()\n",
    "                            trainedModel = trainModel(model,batch,epoch,trainX,trainY)\n",
    "                            #plotLosss(trainedModel)\n",
    "                            loss = np.sqrt(trainedModel.history.history['loss'][-1])\n",
    "                            #print ('RMSE loss :', loss)\n",
    "                            trainPredict, testPredict, predicted = predict(trainedModel,trainX, testX)\n",
    "                            #plotCompare(finalData, testPredict, split)\n",
    "\n",
    "                            for profit in profits:\n",
    "                                decision = calculateDecision(test, testPredict, step, profit*profitMult)\n",
    "\n",
    "                                #plotResult(finalData, testPredict,split, profit, decision)\n",
    "                                #plotProfit(finalData, split, decision)\n",
    "                                coincide, nocoincide = calculateProfit(finalData, decision)\n",
    "                                if coincide+nocoincide == 0:\n",
    "                                    ben = '-'\n",
    "                                else:\n",
    "                                    ben = str(round(coincide/(coincide+nocoincide)*100,2))+'%'\n",
    "                                df = pd.concat([df, pd.DataFrame({\n",
    "                                    'int': [interval],\n",
    "                                    'algo': [algorithm],\n",
    "                                    'step':[\"{:2}\".format(step)],\n",
    "                                    'unit':[unit],\n",
    "                                    'bat':[\"{:3}\".format(batch)],\n",
    "                                    'epo':[\"{:2}\".format(epoch)],\n",
    "                                    'profit':[\"{:2.5f}\".format(profit*profitMult)],\n",
    "                                    'loss': [\"{:2.5f}\".format(loss)],\n",
    "                                    'good': [\"{:4}\".format(coincide)],\n",
    "                                    'bad': [\"{:4}\".format(nocoincide)],\n",
    "                                    'benefit': [ben]\n",
    "                                })])\n",
    "                                print(df.iloc[-1:].to_string(header=False, index=False))\n",
    "                                df.to_csv('/content/drive/MyDrive/Colab Notebooks/TFG/Tests_Results-'+stock + str(dates)+ \\\n",
    "                                          str(intervals)+str(algorithms)+str(steps)+str(units)+str(batchs)+str(epochs)+str(profitMult)+'.csv', index=False)\n",
    "\n",
    "    df.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando 72 tests:\n",
      "30min RNN  2 100   2 0.00000  1 0.04647 2288 2510 47.69%\n",
      "30min RNN  2 100   2 0.00001  1 0.04647 2278 2496 47.72%\n",
      "30min RNN  2 100   2 0.00010  1 0.04647 2149 2411 47.13%\n",
      "30min RNN  2 300   2 0.00000  1 0.04154 2328 2473 48.49%\n",
      "30min RNN  2 300   2 0.00001  1 0.04154 2313 2460 48.46%\n",
      "30min RNN  2 300   2 0.00010  1 0.04154 2144 2338 47.84%\n",
      "30min RNN  2 500   2 0.00000  1 0.04315 2331 2471 48.54%\n",
      "30min RNN  2 500   2 0.00001  1 0.04315 2320 2458 48.56%\n",
      "30min RNN  2 500   2 0.00010  1 0.04315 2161 2364 47.76%\n",
      "30min RNN  5 100   2 0.00000  1 0.05591 2341 2460 48.76%\n",
      "30min RNN  5 100   2 0.00001  1 0.05591 2331 2448 48.78%\n",
      "30min RNN  5 100   2 0.00010  1 0.05591 2212 2371 48.27%\n",
      "30min RNN  5 300   2 0.00000  1 0.04368 2292 2505 47.78%\n",
      "30min RNN  5 300   2 0.00001  1 0.04368 2284 2501 47.73%\n",
      "30min RNN  5 300   2 0.00010  1 0.04368 2164 2435 47.05%\n",
      "30min RNN  5 500   2 0.00000  1 0.04503 2353 2449 49.0%\n",
      "30min RNN  5 500   2 0.00001  1 0.04503 2347 2449 48.94%\n",
      "30min RNN  5 500   2 0.00010  1 0.04503 2263 2437 48.15%\n",
      "30min RNN 10 100   2 0.00000  1 0.05164 2295 2506 47.8%\n",
      "30min RNN 10 100   2 0.00001  1 0.05164 2280 2496 47.74%\n",
      "30min RNN 10 100   2 0.00010  1 0.05164 2179 2441 47.16%\n",
      "30min RNN 10 300   2 0.00000  1 0.04708 2363 2434 49.26%\n",
      "30min RNN 10 300   2 0.00001  1 0.04708 2345 2422 49.19%\n",
      "30min RNN 10 300   2 0.00010  1 0.04708 2149 2280 48.52%\n",
      "30min RNN 10 500   2 0.00000  1 0.04403 2331 2470 48.55%\n",
      "30min RNN 10 500   2 0.00001  1 0.04403 2326 2458 48.62%\n",
      "30min RNN 10 500   2 0.00010  1 0.04403 2233 2415 48.04%\n",
      "30min RNN 20 100   2 0.00000  1 0.04950 2377 2421 49.54%\n",
      "30min RNN 20 100   2 0.00001  1 0.04950 2363 2413 49.48%\n",
      "30min RNN 20 100   2 0.00010  1 0.04950 2230 2306 49.16%\n",
      "30min RNN 20 300   2 0.00000  1 0.04340 2353 2444 49.05%\n",
      "30min RNN 20 300   2 0.00001  1 0.04340 2338 2428 49.06%\n",
      "30min RNN 20 300   2 0.00010  1 0.04340 2116 2287 48.06%\n",
      "30min RNN 20 500   2 0.00000  1 0.04549 2350 2451 48.95%\n",
      "30min RNN 20 500   2 0.00001  1 0.04549 2336 2447 48.84%\n",
      "30min RNN 20 500   2 0.00010  1 0.04549 2233 2416 48.03%\n",
      "30min LSTM  2 100   2 0.00000  1 0.03268 2329 2469 48.54%\n",
      "30min LSTM  2 100   2 0.00001  1 0.03268 2323 2462 48.55%\n",
      "30min LSTM  2 100   2 0.00010  1 0.03268 2212 2426 47.69%\n",
      "30min LSTM  2 300   2 0.00000  1 0.03039 2309 2490 48.11%\n",
      "30min LSTM  2 300   2 0.00001  1 0.03039 2299 2482 48.09%\n",
      "30min LSTM  2 300   2 0.00010  1 0.03039 2182 2429 47.32%\n",
      "30min LSTM  2 500   2 0.00000  1 0.02810 2291 2510 47.72%\n",
      "30min LSTM  2 500   2 0.00001  1 0.02810 2281 2501 47.7%\n",
      "30min LSTM  2 500   2 0.00010  1 0.02810 2161 2448 46.89%\n",
      "30min LSTM  5 100   2 0.00000  1 0.03296 2327 2471 48.5%\n",
      "30min LSTM  5 100   2 0.00001  1 0.03296 2314 2467 48.4%\n",
      "30min LSTM  5 100   2 0.00010  1 0.03296 2206 2424 47.65%\n",
      "30min LSTM  5 300   2 0.00000  1 0.03157 2295 2506 47.8%\n",
      "30min LSTM  5 300   2 0.00001  1 0.03157 2286 2497 47.79%\n",
      "30min LSTM  5 300   2 0.00010  1 0.03157 2175 2425 47.28%\n",
      "30min LSTM  5 500   2 0.00000  1 0.03160 2318 2484 48.27%\n",
      "30min LSTM  5 500   2 0.00001  1 0.03160 2307 2474 48.25%\n",
      "30min LSTM  5 500   2 0.00010  1 0.03160 2191 2407 47.65%\n",
      "30min LSTM 10 100   2 0.00000  1 0.03525 2314 2488 48.19%\n",
      "30min LSTM 10 100   2 0.00001  1 0.03525 2307 2483 48.16%\n",
      "30min LSTM 10 100   2 0.00010  1 0.03525 2200 2432 47.5%\n",
      "30min LSTM 10 300   2 0.00000  1 0.03451 2295 2501 47.85%\n",
      "30min LSTM 10 300   2 0.00001  1 0.03451 2288 2493 47.86%\n",
      "30min LSTM 10 300   2 0.00010  1 0.03451 2178 2421 47.36%\n",
      "30min LSTM 10 500   2 0.00000  1 0.03351 2329 2469 48.54%\n",
      "30min LSTM 10 500   2 0.00001  1 0.03351 2322 2457 48.59%\n",
      "30min LSTM 10 500   2 0.00010  1 0.03351 2169 2358 47.91%\n",
      "30min LSTM 20 100   2 0.00000  1 0.03392 2325 2476 48.43%\n",
      "30min LSTM 20 100   2 0.00001  1 0.03392 2313 2470 48.36%\n",
      "30min LSTM 20 100   2 0.00010  1 0.03392 2226 2417 47.94%\n",
      "30min LSTM 20 300   2 0.00000  1 0.03269 2303 2498 47.97%\n",
      "30min LSTM 20 300   2 0.00001  1 0.03269 2294 2493 47.92%\n",
      "30min LSTM 20 300   2 0.00010  1 0.03269 2188 2423 47.45%\n",
      "30min LSTM 20 500   2 0.00000  1 0.03584 2312 2488 48.17%\n",
      "30min LSTM 20 500   2 0.00001  1 0.03584 2302 2480 48.14%\n",
      "30min LSTM 20 500   2 0.00010  1 0.03584 2181 2405 47.56%\n"
     ]
    }
   ],
   "source": [
    "split = 0.7\n",
    "stock = 'AAPL'\n",
    "dates = ['2023']\n",
    "profitMult=0.000001\n",
    "\n",
    "intervals = ['1min']\n",
    "algorithms = ['RNN', 'LSTM']\n",
    "steps   = [5, 10, 20]\n",
    "units   = [50, 100, 150]\n",
    "batchs  = [16,64,128]\n",
    "epochs  = [5, 10]\n",
    "profits = [1,10,100,1000]\n",
    "\n",
    "numberoftests = len(intervals)*len(algorithms)*len(steps)*len(units)*len(batchs)*len(profits)*len(epochs)\n",
    "print ('Ejecutando', numberoftests, 'tests:')\n",
    "\n",
    "runTest(split, stock, dates,profitMult,intervals, algorithms, steps, units, batchs, profits, epochs)\n",
    "print(\"Ejecución finalizada\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
