{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZlLIu7uE5ma"
   },
   "source": [
    "# Stock Prediction\n",
    "### Ignacio Fern√°ndez Adrados\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "seE3JuEGE5mh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # type: ignore\n",
    "\n",
    "def getStockDataFrame (stock, years):\n",
    "    STOCK = stock\n",
    "    YEARS = years\n",
    "\n",
    "    file = None\n",
    "    for year in YEARS:\n",
    "        FILE='Datasets/Stock-'+STOCK+'-'+year+'.csv'\n",
    "        ds=pd.read_csv(FILE, sep=',')\n",
    "        file = pd.concat([file,ds])\n",
    "    file = file.sort_values(by='timestamp', ascending=True)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX9Mv-nZFlXk",
    "outputId": "2a025661-a286-4991-9260-66628ec2a250"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def groupStocks(dataset, n, datefilter):\n",
    "\n",
    "    N=n     #Minutos agrupados\n",
    "    DATEFILTER=datefilter #Filtro de fecha\n",
    "    file = dataset\n",
    "    \n",
    "    df = file[file['timestamp'].str.startswith(DATEFILTER)]\n",
    "    df=pd.DataFrame(df)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    dfgroup = pd.DataFrame(df.groupby(pd.Grouper(key='timestamp', freq=N)).first()['open'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).last()['close'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).min()['low'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).max()['high'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N, offset='60min')).sum()['volume'])\n",
    "    dfgroup = pd.DataFrame(pd.to_datetime(dfgroup.index[1:])).join(dfgroup[:-1].reset_index(drop=True))\n",
    "    return dfgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "z2bs-Qemi12t",
    "outputId": "161bc113-e1f6-4b25-d8d9-b56f9f078f66"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_rsi(close, lookback):\n",
    "    ret = close.diff()\n",
    "    up = []\n",
    "    down = []\n",
    "    for i in range(len(ret)):\n",
    "        if ret[i] < 0:\n",
    "            up.append(0)\n",
    "            down.append(ret[i])\n",
    "        else:\n",
    "            up.append(ret[i])\n",
    "            down.append(0)\n",
    "    up_series = pd.Series(up)\n",
    "    down_series = pd.Series(down).abs()\n",
    "    up_ewm = up_series.ewm(com = lookback - 1, adjust = False).mean()\n",
    "    down_ewm = down_series.ewm(com = lookback - 1, adjust = False).mean()\n",
    "    rs = up_ewm/down_ewm\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    rsi_df = pd.DataFrame(rsi).rename(columns = {0:'rsi'}).set_index(close.index)\n",
    "    rsi_df = rsi_df.dropna()\n",
    "    return rsi_df[3:]\n",
    "\n",
    "def getIndicators(dataset):\n",
    "    \n",
    "    dfgroup = dataset\n",
    "\n",
    "    dfgroup['EMA7']= dfgroup['close'].ewm(span=7, adjust=False).mean()\n",
    "    dfgroup['MACD']= dfgroup['close'].ewm(span=12, adjust=False).mean()- dfgroup['close'].ewm(span=26, adjust=False).mean()\n",
    "    dfgroup['SignalMACD'] = dfgroup['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    dfgroup['RSI'] = get_rsi(dfgroup['close'], 14)\n",
    "    dfgroup = dfgroup.dropna()\n",
    "    dfgroup = dfgroup.reset_index(drop=True)\n",
    "    return dfgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TBisHNoeE5mo",
    "outputId": "314904d0-9fde-4c6f-96fd-1eaaff6387dc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize(dataset):\n",
    "    #Normalise data into (0,1) range\n",
    "    normData=dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    #normData[['open']] = scaler.fit_transform(normData[['open']])\n",
    "    normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']] = \\\n",
    "        scaler.fit_transform(normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']])\n",
    "    return normData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "hY9NX9AeE5mp",
    "outputId": "6d446865-54a0-4bb4-b540-46dc88bb3e9d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotDataset(dataset):\n",
    "\n",
    "    normData = dataset\n",
    "    \n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Dataset 'Close' data \")\n",
    "    plt.plot(normData['close'],color='black')\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] == -1,normData['close'], None), color=\"red\", marker=\"v\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] ==  1,normData['close'], None), color=\"blue\", marker=\"^\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W41DlLEoE5mq"
   },
   "source": [
    "### Split the values in train and test\n",
    "\n",
    "So, we took only 25% of the data as training samples and set aside the rest of the data for testing.\n",
    "\n",
    "Looking at the time-series plot, we think **it is not easy for a standard model to come up with correct trend predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "es2T4CuCE5mr",
    "outputId": "7e2cbeb1-c779-415b-ba2d-295f95a7a854"
   },
   "outputs": [],
   "source": [
    "def splitData(dataset, split, step):\n",
    "\n",
    "    S=split\n",
    "    step = step\n",
    "    normData = dataset\n",
    "\n",
    "    split = int(len(normData) * S)\n",
    "    #values = normData.values\n",
    "    #print(values)\n",
    "    train = normData[:split]#.drop(['buysell'],axis=1)\n",
    "    test = pd.concat([train.tail(step),normData[split:]]).reset_index(drop=True)\n",
    "\n",
    "    #print(\"Train data length:\", train.shape)\n",
    "    #print(\"Test data length:\", test.shape)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "yq8Pr6juE5ms",
    "outputId": "0870926c-f065-418c-e5bd-07c141e27bce"
   },
   "outputs": [],
   "source": [
    "def plotSplitDataset(dataset, split):\n",
    "    \n",
    "    normData = dataset\n",
    "    split = int(len(normData) * split)\n",
    "\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Dataset 'Close' data split\")\n",
    "    plt.plot(normData.index.values,normData['close'],c='black')\n",
    "    plt.axvline(normData.index[split], c=\"r\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] == -1,normData['close'], None), color=\"red\",  marker=\"v\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] ==  1,normData['close'], None), color=\"blue\", marker=\"^\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4No4lvOSE5mu"
   },
   "source": [
    "### Converting to a multi-dimensional array\n",
    "Next, we'll convert test and train data into the matrix with step value as it has shown above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8J-93wpyE5mu",
    "outputId": "1deefe1b-450d-4a34-98c4-c526e71c4688"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convertToMatrix(data, step):\n",
    "    X, Y =[], []\n",
    "    for i in range(len(data)-step):\n",
    "        d=i+step\n",
    "        #print(i, d, data[i:d)\n",
    "        X.append(data[i:d])\n",
    "        Y.append(data[d,1])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def dataset2Matrix(train, test, step):\n",
    "    trainX,trainY =convertToMatrix(train.to_numpy(),step)\n",
    "    testX,testY =convertToMatrix(test.to_numpy(),step)\n",
    "    #print(trainY)\n",
    "    #print(\"Training data shape:\", trainX.shape,', ',trainY.shape)\n",
    "    #print(\"Test data shape:\", testX.shape,', ',testY.shape)\n",
    "    return trainX, trainY, testX, testY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfLqFjJxE5mw"
   },
   "source": [
    "### Keras model with `SimpleRNN` layer\n",
    "\n",
    "- 256 neurons in the RNN layer\n",
    "- 32 denurons in the densely connected layer\n",
    "- a single neuron for the output layer\n",
    "- ReLu activation\n",
    "- learning rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "4BjedTvlE5mw",
    "outputId": "a224d1e0-e032-4e1b-d276-12049d88cebb"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, LSTM, Dropout # type: ignore\n",
    "\n",
    "def createModel(type, units, trainX, step):\n",
    "    UNITS = units #num_units: Number of units of a the simple RNN layer\n",
    "    DENSEUNITS = 32 #Number of neurons in the dense layer followed by the RNN layer\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input((step, trainX.shape[2])))\n",
    "    if type==\"LSTM\":\n",
    "        model.add(LSTM(units=UNITS, activation=\"tanh\",return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=UNITS//2, activation=\"tanh\"))\n",
    "        model.add(Dropout(0.2))      \n",
    "    elif type == \"RNN\":\n",
    "        model.add(SimpleRNN(units=UNITS, activation=\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(SimpleRNN(units=UNITS//2, activation=\"relu\"))\n",
    "        model.add(Dropout(0.2))     \n",
    "    model.add(Dense(DENSEUNITS, activation=\"tanh\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mse'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg4jkMzRE5mz"
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyGK1fyFE5mz",
    "outputId": "9a183877-c6d8-4587-802c-12e4f8c4e138"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback # type: ignore\n",
    "\n",
    "'''class MyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        #if (epoch+1) % 10 == 0 and epoch>0:\n",
    "            print(\"Epoch number {} done\".format(epoch+1))\n",
    "'''\n",
    "def trainModel(model, batch, epochs, trainX, trainY):\n",
    "    batch_size=batch\n",
    "    num_epochs = epochs\n",
    "\n",
    "    model.fit(trainX,trainY,\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            #callbacks=[MyCallback()],verbose=0\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8u8PJjdE5m0"
   },
   "source": [
    "### Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "UoYGhk7EE5m0",
    "outputId": "4f2b1a4c-31cc-4eab-e5d0-f86b9c6489bd"
   },
   "outputs": [],
   "source": [
    "def plotLosss(model):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.title(\"RMSE loss over epochs\",fontsize=16)\n",
    "    plt.plot(np.sqrt(model.history.history['loss']),c='k',lw=2)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Epochs\",fontsize=14)\n",
    "    plt.ylabel(\"Root-mean-squared error\",fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d_0G0OpE5m1"
   },
   "source": [
    "### Predictions\n",
    "Note that the model was fitted only with the `trainX` and `trainY` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-cH3SZuE5m2",
    "outputId": "56231db1-6f88-4b7e-8352-aaa6520a042e"
   },
   "outputs": [],
   "source": [
    "def predict(model, trainX, testX):\n",
    "    \n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict= model.predict(testX)\n",
    "    predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "    print(trainPredict.shape)\n",
    "    print(testPredict.shape)\n",
    "\n",
    "    return trainPredict, testPredict, predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enWdLcInE5m3"
   },
   "source": [
    "### Comparing it with the ground truth (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "MoxCTnZqE5m3",
    "outputId": "32af9acf-1724-414b-e43f-8f5b0ce90759"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plotCompare(normData, testPredict, split):\n",
    "\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "    index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black', label='Ground Truth')\n",
    "    plt.plot(testPredict[OFFSET:],color='blue', label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDecision(test, testPredict, step, profit):\n",
    "\n",
    "    PROFIT = profit\n",
    "\n",
    "    decision=test['close'].iloc[step:]\n",
    "    decision = decision.diff()\n",
    "    decision = decision.dropna()\n",
    "    decision = np.where(abs(decision)<PROFIT,0,np.sign(decision).astype('int'))\n",
    "    decision = pd.DataFrame(data={'buysell':decision})#.drop(0).reset_index(drop=True)\n",
    "\n",
    "    predictedDecision = pd.DataFrame(data={'buysellPredicted':testPredict[:,0]})\n",
    "    predictedDecision = predictedDecision.diff()\n",
    "    predictedDecision = predictedDecision.dropna()#.reset_index(drop=True)\n",
    "    predictedDecision = np.where(abs(predictedDecision)<PROFIT,0,np.sign(predictedDecision).astype('int'))\n",
    "    predictedDecision = pd.DataFrame(data={'buysellPredicted':predictedDecision[:,0]})\n",
    "\n",
    "    return decision, predictedDecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "Xg5ICE2T8JSa",
    "outputId": "5c4d5a98-1cf4-4899-ca4a-c1cd85f97b4e"
   },
   "outputs": [],
   "source": [
    "def plotResult(normData, testPredict, split, profit, decision, predictedDecision):\n",
    "\n",
    "    PROFIT=profit\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "\n",
    "    \n",
    "\n",
    "    index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black')\n",
    "    plt.plot(testPredict[OFFSET:],color='blue')\n",
    "\n",
    "    x = decision.iloc[OFFSET:].reset_index(drop=True).index\n",
    "    y = normData['close'].iloc[len(normData)-len(predictedDecision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "\n",
    "    plt.scatter(x, np.where(decision['buysell'].iloc[OFFSET:] == -1,y, None), color=\"red\",  marker=\"v\", label='Ground Truth Sell')\n",
    "    plt.scatter(x, np.where(decision['buysell'].iloc[OFFSET:] ==  1,y, None), color=\"blue\", marker=\"^\", label='Ground Truth Buy')\n",
    "\n",
    "    plt.scatter(x, np.where(predictedDecision['buysellPredicted'].iloc[OFFSET:] == -1,y-0.015, None), color=\"orange\",  marker=\"v\", label='Prediction Sell')\n",
    "    plt.scatter(x, np.where(predictedDecision['buysellPredicted'].iloc[OFFSET:] ==  1,y+0.015, None), color=\"green\",  marker=\"^\", label='Prediction Buy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "K8VIy1uYFhdb",
    "outputId": "66fae12b-291b-4cce-a052-b57ee39fd236"
   },
   "outputs": [],
   "source": [
    "def plotProfit(normData, split, decision, predictedDecision):\n",
    "\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "    index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black')\n",
    "    #plt.plot(testPredict[OFFSET:],color='blue')\n",
    "\n",
    "    x = decision.iloc[OFFSET:].reset_index(drop=True).index\n",
    "    y = normData['close'].iloc[len(normData)-len(predictedDecision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "\n",
    "    plt.scatter(x, np.where((decision['buysell'].iloc[OFFSET:] !=  predictedDecision['buysellPredicted'].iloc[OFFSET:]) & (predictedDecision['buysellPredicted'].iloc[OFFSET:] != 0),y, None), color=\"red\", label='Ground Truth Buy')\n",
    "    plt.scatter(x, np.where((decision['buysell'].iloc[OFFSET:] == predictedDecision['buysellPredicted'].iloc[OFFSET:]) & (decision['buysell'].iloc[OFFSET:] != 0),y, None), color=\"green\",  label='Ground Truth Sell')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yN3Hp3azZi3c",
    "outputId": "1a0bbe4e-1fc8-413a-cd3c-aa7b277e5c31"
   },
   "outputs": [],
   "source": [
    "def calculateProfit(normData, decision, predictedDecision):\n",
    "\n",
    "    OFFSET=0\n",
    "    y = normData['close'].iloc[len(normData)-len(predictedDecision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "\n",
    "    #print(\"Predicciones no coincidentes con el conjunto de pruebas: \", \\\n",
    "    nocoincide =np.count_nonzero(np.where((decision['buysell'].iloc[OFFSET:] !=  predictedDecision['buysellPredicted'].iloc[OFFSET:]) \\\n",
    "          & (predictedDecision['buysellPredicted'].iloc[OFFSET:] != 0),y, None))#)\n",
    "    #print(\"Predicciones coincidentes con el conjunto de pruebas: \", \\\n",
    "    coincide=np.count_nonzero(np.where((decision['buysell'].iloc[OFFSET:] == predictedDecision['buysellPredicted'].iloc[OFFSET:]) \\\n",
    "          & (decision['buysell'].iloc[OFFSET:] != 0),y, None))#)\n",
    "    return coincide, nocoincide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating iteration  0\n",
      "Epoch 1/5\n",
      "\u001b[1m59563/59563\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 10ms/step - loss: 5.8906e-04 - mse: 5.8906e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m34712/59563\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m3:21\u001b[0m 8ms/step - loss: 6.2728e-05 - mse: 6.2728e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m model \u001b[38;5;241m=\u001b[39m createModel(algorithm, unit,trainX, step)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#model.summary()\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m trainedModel \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#plotLosss(trainedModel)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(trainedModel\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[23], line 12\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(model, batch, epochs, trainX, trainY)\u001b[0m\n\u001b[0;32m      9\u001b[0m batch_size\u001b[38;5;241m=\u001b[39mbatch\n\u001b[0;32m     10\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m epochs\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#callbacks=[MyCallback()],verbose=0\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "split = 0.7\n",
    "stock = 'AAPL'\n",
    "dates = ['2022','2023']\n",
    "\n",
    "intervals = ['10min','1h','1D']\n",
    "algorithms = ['LSTM', 'RNN']\n",
    "steps = range(5, 16, 5)\n",
    "units = range(100,500,100)\n",
    "batchs = range(5,100, 20)\n",
    "profits = range(1, 10, 5)\n",
    "epochs = range (5,50,50)\n",
    "\n",
    "df = None\n",
    "i=0\n",
    "for interval in intervals:\n",
    "    for algorithm in algorithms:\n",
    "        for step in steps:\n",
    "            for unit in units:\n",
    "                for batch in batchs:\n",
    "                    for profit in profits:\n",
    "                        for epoch in epochs:\n",
    "                            print('Calculating iteration ', i)\n",
    "                            i += 1\n",
    "                            s1 = getStockDataFrame(stock, dates )\n",
    "                            s2 = groupStocks(s1,interval, '')\n",
    "                            s2 = s2.drop(['timestamp'],axis=1)\n",
    "                            s3 = getIndicators(s2)\n",
    "                            s4 = normalize(s3)\n",
    "                            #plotDataset(s4)\n",
    "                            train, test = splitData(s4, split, step)\n",
    "                            #plotSplitDataset(s4, split)\n",
    "                            trainX, trainY, testX, testY = dataset2Matrix(train, test, step)\n",
    "                            model = createModel(algorithm, unit,trainX, step)\n",
    "                            #model.summary()\n",
    "                            trainedModel = trainModel(model,batch,epoch,trainX,trainY)\n",
    "                            #plotLosss(trainedModel)\n",
    "                            loss = np.sqrt(trainedModel.history.history['loss'][-1])\n",
    "                            #print ('RMSE loss :', loss)\n",
    "                            trainPredict, testPredict, predicted = predict(trainedModel,trainX, testX)\n",
    "                            #plotCompare(s4, testPredict, split)\n",
    "                            decision, predictedDecision = calculateDecision(test, testPredict, step, profit)\n",
    "                            #plotResult(s4, testPredict,split, profit, decision, predictedDecision)\n",
    "                            plotProfit(s4, split, decision, predictedDecision)\n",
    "                            coincide, nocoincide = calculateProfit(s4, decision, predictedDecision)\n",
    "                            df = pd.concat([df, pd.DataFrame({\\\n",
    "                                'interval': [interval],\\\n",
    "                                'algo': [algorithm],\\\n",
    "                                'step':[step], \\\n",
    "                                'units':[unit],\\\n",
    "                                'batchs':[batch],\\\n",
    "                                'profit':[profit*0.1],\\\n",
    "                                'epochs':[epoch],\\\n",
    "                                'loss': [loss],\\\n",
    "                                'coincide': [coincide],\\\n",
    "                                'nocoincide': [nocoincide]\n",
    "                             })])\n",
    "\n",
    "df.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
