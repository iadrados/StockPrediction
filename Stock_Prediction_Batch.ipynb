{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZlLIu7uE5ma"
   },
   "source": [
    "# Stock Prediction\n",
    "### Ignacio Fernández Adrados\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy \n",
    "! pip install pandas\n",
    "! pip install scikit-learn\n",
    "! pip install matplotlib\n",
    "! pip install numpy\n",
    "! pip install keras\n",
    "! pip install tensorflow\n",
    "! pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seE3JuEGE5mh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # type: ignore\n",
    "\n",
    "def getStockDataFrame (stock, years):\n",
    "    STOCK = stock\n",
    "    YEARS = years\n",
    "\n",
    "    file = None\n",
    "    for year in YEARS:\n",
    "        FILE='Datasets/Stock-'+STOCK+'-'+year+'.csv'\n",
    "        ds=pd.read_csv(FILE, sep=',')\n",
    "        file = pd.concat([file,ds])\n",
    "    file = file.sort_values(by='timestamp', ascending=True)\n",
    "    return file\n",
    "#getStockDataFrame('AAPL', ['2022','2023'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX9Mv-nZFlXk",
    "outputId": "2a025661-a286-4991-9260-66628ec2a250"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def groupStocks(dataset, n, datefilter):\n",
    "\n",
    "    N=n     #Minutos agrupados\n",
    "    DATEFILTER=datefilter #Filtro de fecha\n",
    "    file = dataset\n",
    "    \n",
    "    df = file[file['timestamp'].str.startswith(DATEFILTER)]\n",
    "    df=pd.DataFrame(df)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    dfgroup = pd.DataFrame(df.groupby(pd.Grouper(key='timestamp', freq=N)).first()['open'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).last()['close'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).min()['low'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).max()['high'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).sum()['volume'])\n",
    "    #dfgroup = dfgroup[:-1].reset_index(drop=True)\n",
    "    dfgroup = pd.DataFrame(pd.to_datetime(dfgroup.index[:])).join(dfgroup.reset_index(drop=True))\n",
    "    dfgroup = dfgroup.dropna().reset_index(drop=True)\n",
    "    return dfgroup\n",
    "#xxx = groupStocks(getStockDataFrame('AAPL', ['2022']), '1D', '')\n",
    "#xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "z2bs-Qemi12t",
    "outputId": "161bc113-e1f6-4b25-d8d9-b56f9f078f66"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_rsi(close, lookback):\n",
    "    ret = close.diff()\n",
    "    up = []\n",
    "    down = []\n",
    "    for i in range(len(ret)):\n",
    "        if ret[i] < 0:\n",
    "            up.append(0)\n",
    "            down.append(ret[i])\n",
    "        else:\n",
    "            up.append(ret[i])\n",
    "            down.append(0)\n",
    "    up_series = pd.Series(up)\n",
    "    down_series = pd.Series(down).abs()\n",
    "    up_ewm = up_series.ewm(com = lookback - 1, adjust = False).mean()\n",
    "    down_ewm = down_series.ewm(com = lookback - 1, adjust = False).mean()\n",
    "    rs = up_ewm/down_ewm\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    rsi_df = pd.DataFrame(rsi).rename(columns = {0:'rsi'}).set_index(close.index)\n",
    "    rsi_df = rsi_df.dropna()\n",
    "    return rsi_df[3:]\n",
    "\n",
    "def getIndicators(dataset):\n",
    "    \n",
    "    dfgroup = dataset\n",
    "\n",
    "    dfgroup['EMA7']= dfgroup['close'].ewm(span=7, adjust=False).mean()\n",
    "    dfgroup['MACD']= dfgroup['close'].ewm(span=12, adjust=False).mean()- dfgroup['close'].ewm(span=26, adjust=False).mean()\n",
    "    dfgroup['SignalMACD'] = dfgroup['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    dfgroup['RSI'] = get_rsi(dfgroup['close'], 14)\n",
    "    dfgroup = dfgroup.dropna()\n",
    "    dfgroup = dfgroup.reset_index(drop=True)\n",
    "    return dfgroup\n",
    "\n",
    "#getIndicators(xxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadiendo sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewsDataFrame(stock, dates, interval, stockDataFrame, relevance):\n",
    "   \n",
    "    file = None\n",
    "    for year in dates:\n",
    "        FILE='Datasets/News-'+stock+'-'+year+'.csv'\n",
    "        ds=pd.read_csv(FILE, sep=',')\n",
    "        file = pd.concat([file,ds])\n",
    "    file = file.sort_values(by='date', ascending=True)\n",
    "    \n",
    "    file['date'] = pd.to_datetime(file['date'], format='%Y%m%dT%H%M%S')\n",
    "    file = file.drop(['title','summary','ticker'], axis=1)\n",
    "    file = file[file['relevance']>=relevance]\n",
    "    \n",
    "    dfgroup = pd.DataFrame(file.groupby(pd.Grouper(key='date', freq=interval)).last()['relevance'])\n",
    "    dfgroup = dfgroup.join(file.groupby(pd.Grouper(key='date', freq=interval)).last()['sentiment'])\n",
    "    dfgroup = pd.DataFrame(pd.to_datetime(dfgroup.index[:])).join(dfgroup.reset_index(drop=True))\n",
    "    dfgroup = dfgroup.fillna(0)\n",
    "    stockDataFrame['timestamp'] = pd.to_datetime(stockDataFrame['timestamp'])\n",
    "    res = stockDataFrame.join(dfgroup.set_index(\"date\"), on='timestamp', how='left')\n",
    "    res = res.fillna(0)\n",
    "    res = res.reset_index(drop=True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TBisHNoeE5mo",
    "outputId": "314904d0-9fde-4c6f-96fd-1eaaff6387dc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize(dataset):\n",
    "    #Normalise data into (0,1) range\n",
    "    normData=dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    #normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']] = \\\n",
    "    #    scaler.fit_transform(normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']])\n",
    "    #print(normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']].head(1))\n",
    "    c=normData.columns.values\n",
    "    normData[c] = scaler.fit_transform(normData[c])\n",
    "    return normData\n",
    "\n",
    "##################################################3\n",
    "#data = getStockDataFrame('AAPL', ['2023'])\n",
    "#indicatorData = groupStocks(data, '1D', '')\n",
    "#indicatorData = getNewsDataFrame('AAPL', ['2023'], '1D', indicatorData, 0)\n",
    "#indicatorData = indicatorData.drop(['timestamp'], axis=1)\n",
    "#normalize(indicatorData)\n",
    "##################################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "hY9NX9AeE5mp",
    "outputId": "6d446865-54a0-4bb4-b540-46dc88bb3e9d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotDataset(dataset):\n",
    "\n",
    "    normData = dataset\n",
    "    \n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Dataset 'Close' data \")\n",
    "    plt.plot(normData['close'],color='black')\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] == -1,normData['close'], None), color=\"red\", marker=\"v\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] ==  1,normData['close'], None), color=\"blue\", marker=\"^\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W41DlLEoE5mq"
   },
   "source": [
    "### Split the values in train and test\n",
    "\n",
    "So, we took only 25% of the data as training samples and set aside the rest of the data for testing.\n",
    "\n",
    "Looking at the time-series plot, we think **it is not easy for a standard model to come up with correct trend predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "es2T4CuCE5mr",
    "outputId": "7e2cbeb1-c779-415b-ba2d-295f95a7a854"
   },
   "outputs": [],
   "source": [
    "def splitData(dataset, split, step):\n",
    "\n",
    "    S=split\n",
    "    step = step\n",
    "    normData = dataset\n",
    "\n",
    "    split = int(len(normData) * S)\n",
    "    #values = normData.values\n",
    "    #print(values)\n",
    "    train = normData[:split]#.drop(['buysell'],axis=1)\n",
    "    test = pd.concat([train.tail(step),normData[split:]]).reset_index(drop=True)\n",
    "\n",
    "    #print(\"Train data length:\", train.shape)\n",
    "    #print(\"Test data length:\", test.shape)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "yq8Pr6juE5ms",
    "outputId": "0870926c-f065-418c-e5bd-07c141e27bce"
   },
   "outputs": [],
   "source": [
    "def plotSplitDataset(dataset, split):\n",
    "    \n",
    "    normData = dataset\n",
    "    split = int(len(normData) * split)\n",
    "\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Dataset 'Close' data split\")\n",
    "    plt.plot(normData.index.values,normData['close'],c='black')\n",
    "    plt.axvline(normData.index[split], c=\"r\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] == -1,normData['close'], None), color=\"red\",  marker=\"v\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] ==  1,normData['close'], None), color=\"blue\", marker=\"^\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4No4lvOSE5mu"
   },
   "source": [
    "### Converting to a multi-dimensional array\n",
    "Next, we'll convert test and train data into the matrix with step value as it has shown above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8J-93wpyE5mu",
    "outputId": "1deefe1b-450d-4a34-98c4-c526e71c4688"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convertToMatrix(data, step):\n",
    "    X, Y =[], []\n",
    "    for i in range(len(data)-step):\n",
    "        d=i+step\n",
    "        #print(i, d, data[i:d)\n",
    "        X.append(data[i:d])\n",
    "        Y.append(data[d,1])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def dataset2Matrix(train, test, step):\n",
    "    trainX,trainY =convertToMatrix(train.to_numpy(),step)\n",
    "    testX,testY =convertToMatrix(test.to_numpy(),step)\n",
    "    #print(trainY)\n",
    "    #print(\"Training data shape:\", trainX.shape,', ',trainY.shape)\n",
    "    #print(\"Test data shape:\", testX.shape,', ',testY.shape)\n",
    "    return trainX, trainY, testX, testY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfLqFjJxE5mw"
   },
   "source": [
    "### Keras model with `SimpleRNN` layer\n",
    "\n",
    "- 256 neurons in the RNN layer\n",
    "- 32 denurons in the densely connected layer\n",
    "- a single neuron for the output layer\n",
    "- ReLu activation\n",
    "- learning rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "4BjedTvlE5mw",
    "outputId": "a224d1e0-e032-4e1b-d276-12049d88cebb"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, LSTM, Dropout # type: ignore\n",
    "\n",
    "def createModel(type, units, trainX, step):\n",
    "    UNITS = units #num_units: Number of units of a the simple RNN layer\n",
    "    DENSEUNITS = 32 #Number of neurons in the dense layer followed by the RNN layer\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input((step, trainX.shape[2])))\n",
    "    if type==\"LSTM\":\n",
    "        model.add(LSTM(units=UNITS, activation=\"tanh\",return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=UNITS//2, activation=\"tanh\"))\n",
    "        model.add(Dropout(0.2))      \n",
    "    elif type == \"RNN\":\n",
    "        model.add(SimpleRNN(units=UNITS, activation=\"relu\",return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(SimpleRNN(units=UNITS//2, activation=\"relu\"))\n",
    "        model.add(Dropout(0.2))     \n",
    "    model.add(Dense(DENSEUNITS, activation=\"tanh\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mse'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg4jkMzRE5mz"
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyGK1fyFE5mz",
    "outputId": "9a183877-c6d8-4587-802c-12e4f8c4e138"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback # type: ignore\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        #if (epoch+1) % 10 == 0 and epoch>0:\n",
    "            print(\"Epoch number {} done\".format(epoch+1))\n",
    "\n",
    "def trainModel(model, batch, epochs, trainX, trainY):\n",
    "    batch_size=batch\n",
    "    num_epochs = epochs\n",
    "\n",
    "    model.fit(trainX,trainY,\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=None,verbose=0\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8u8PJjdE5m0"
   },
   "source": [
    "### Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "UoYGhk7EE5m0",
    "outputId": "4f2b1a4c-31cc-4eab-e5d0-f86b9c6489bd"
   },
   "outputs": [],
   "source": [
    "def plotLosss(model):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.title(\"RMSE loss over epochs\",fontsize=16)\n",
    "    plt.plot(np.sqrt(model.history.history['loss']),c='k',lw=2)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Epochs\",fontsize=14)\n",
    "    plt.ylabel(\"Root-mean-squared error\",fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d_0G0OpE5m1"
   },
   "source": [
    "### Predictions\n",
    "Note that the model was fitted only with the `trainX` and `trainY` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-cH3SZuE5m2",
    "outputId": "56231db1-6f88-4b7e-8352-aaa6520a042e"
   },
   "outputs": [],
   "source": [
    "def predict(model, trainX, testX):\n",
    "    trainPredict = model.predict(trainX, verbose=0)\n",
    "    testPredict= model.predict(testX, verbose=0)\n",
    " \n",
    "    #predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "    #print(trainPredict.shape)\n",
    "    #print(testPredict.shape)\n",
    "\n",
    "    return trainPredict, testPredict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enWdLcInE5m3"
   },
   "source": [
    "### Comparing it with the ground truth (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "MoxCTnZqE5m3",
    "outputId": "32af9acf-1724-414b-e43f-8f5b0ce90759"
   },
   "outputs": [],
   "source": [
    "def plotCompare(normData, testPredict, split):\n",
    "\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "    #index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black', label='Ground Truth')\n",
    "    plt.plot(testPredict[OFFSET:],color='blue', label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDecision(test, testPredict, step, profit):\n",
    "\n",
    "    PROFIT = profit\n",
    "\n",
    "    decision=test['close'].iloc[step:]\n",
    "    decision = decision.diff()\n",
    "    decision = decision.dropna()\n",
    "    decision = np.where(abs(decision)<PROFIT,0,np.sign(decision).astype('int'))\n",
    "    decision = pd.DataFrame(data={'buysell':decision})#.drop(0).reset_index(drop=True)\n",
    "\n",
    "    predictedDecision = pd.DataFrame(data={'buysellPredicted':testPredict[:,0]})\n",
    "    predictedDecision = predictedDecision.diff()\n",
    "    predictedDecision = predictedDecision.dropna()#.reset_index(drop=True)\n",
    "    predictedDecision = np.where(abs(predictedDecision)<PROFIT,0,np.sign(predictedDecision).astype('int'))\n",
    "    predictedDecision = pd.DataFrame(data={'buysellPredicted':predictedDecision[:,0]})\n",
    "\n",
    "    decision = decision.join(predictedDecision)\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "Xg5ICE2T8JSa",
    "outputId": "5c4d5a98-1cf4-4899-ca4a-c1cd85f97b4e"
   },
   "outputs": [],
   "source": [
    "def plotResult(normData, testPredict, split, profit, decision):\n",
    "\n",
    "    PROFIT=profit\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)    \n",
    "\n",
    "    index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black')\n",
    "    plt.plot(testPredict[OFFSET:],color='blue')\n",
    "\n",
    "    x = decision.iloc[OFFSET:].reset_index(drop=True).index\n",
    "    y = normData['close'].iloc[len(normData)-len(decision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "\n",
    "    plt.scatter(x, np.where(decision['buysell'].iloc[OFFSET:] == -1,y, None), color=\"red\",  marker=\"v\", label='Ground Truth Sell')\n",
    "    plt.scatter(x, np.where(decision['buysell'].iloc[OFFSET:] ==  1,y, None), color=\"blue\", marker=\"^\", label='Ground Truth Buy')\n",
    "\n",
    "    plt.scatter(x, np.where(decision['buysellPredicted'].iloc[OFFSET:] == -1,y-0.015, None), color=\"orange\",  marker=\"v\", label='Prediction Sell')\n",
    "    plt.scatter(x, np.where(decision['buysellPredicted'].iloc[OFFSET:] ==  1,y+0.015, None), color=\"green\",  marker=\"^\", label='Prediction Buy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "K8VIy1uYFhdb",
    "outputId": "66fae12b-291b-4cce-a052-b57ee39fd236"
   },
   "outputs": [],
   "source": [
    "def plotProfit(normData, split, decision):\n",
    "\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "    index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black')\n",
    "    #plt.plot(testPredict[OFFSET:],color='blue')\n",
    "\n",
    "    x = decision.iloc[OFFSET:].reset_index(drop=True).index\n",
    "    y = normData['close'].iloc[len(normData)-len(decision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "\n",
    "    plt.scatter(x, np.where((decision['buysell'].iloc[OFFSET:] !=  decision['buysellPredicted'].iloc[OFFSET:]) & (decision['buysellPredicted'].iloc[OFFSET:] != 0),y, None), color=\"red\", label='Ground Truth Buy')\n",
    "    plt.scatter(x, np.where((decision['buysell'].iloc[OFFSET:] == decision['buysellPredicted'].iloc[OFFSET:]) & (decision['buysell'].iloc[OFFSET:] != 0),y, None), color=\"green\",  label='Ground Truth Sell')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yN3Hp3azZi3c",
    "outputId": "1a0bbe4e-1fc8-413a-cd3c-aa7b277e5c31"
   },
   "outputs": [],
   "source": [
    "def calculateProfit(normData, decision):\n",
    "\n",
    "    OFFSET=0\n",
    "    y = normData['close'].iloc[len(normData)-len(decision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "    \n",
    "    #print(\"Predicciones no coincidentes con el conjunto de pruebas: \", \\\n",
    "    nocoincide =np.count_nonzero(np.where((decision['buysell'].iloc[OFFSET:] !=  decision['buysellPredicted'].iloc[OFFSET:]) \\\n",
    "          & (decision['buysellPredicted'].iloc[OFFSET:] != 0),y, None))#)\n",
    "    #print(\"Predicciones coincidentes con el conjunto de pruebas: \", \\\n",
    "    coincide=np.count_nonzero(np.where((decision['buysell'].iloc[OFFSET:] == decision['buysellPredicted'].iloc[OFFSET:]) \\\n",
    "          & (decision['buysell'].iloc[OFFSET:] != 0),y, None))#)\n",
    "    return coincide, nocoincide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  getFinBERTdata(stock, dates):\n",
    "    \n",
    "    from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "    #import transformers\n",
    "\n",
    "    finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "    tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "    nlp = pipeline(\"text-classification\", model=finbert, tokenizer=tokenizer)\n",
    "    '''\n",
    "    results = nlp(['growth is strong and we have plenty of liquidity.', \n",
    "               'there is a shortage of capital, and we need extra financing.',\n",
    "              'formulation patents might protect Vasotec to a limited extent.'])\n",
    "    print(results)\n",
    "    '''\n",
    "    file = None\n",
    "    for year in dates:\n",
    "        FILE='Datasets/News-'+stock+'-'+year+'.csv'\n",
    "        ds=pd.read_csv(FILE, sep=',')\n",
    "        file = pd.concat([file,ds])\n",
    "    file = file.sort_values(by='date', ascending=True)\n",
    "    file = file[file.relevance >0.7].reset_index(drop=True)\n",
    "\n",
    "    headlines_array = np.array(file)\n",
    "    headlines_list = list(headlines_array[:,1])\n",
    "    \n",
    "    results =nlp(headlines_list)\n",
    "    #print(len(results))\n",
    "    pdr = pd.DataFrame(results)\n",
    "    #print(pdr)\n",
    "    file[\"FinBertScore\"]= pdr[\"score\"]\n",
    "    file[\"FinBertLabel\"]= pdr[\"label\"]\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFinbertNewsDataFrame(data, newsdata, interval):\n",
    "    \n",
    "    file = newsdata.sort_values(by='date', ascending=True)\n",
    "    file['date'] = pd.to_datetime(file['date'], format='%Y%m%dT%H%M%S')\n",
    "    file = file.drop(['title','summary','ticker', 'relevance','sentiment', 'FinBertLabel'], axis=1)\n",
    "        \n",
    "    dfgroup = pd.DataFrame(file.groupby(pd.Grouper(key='date', freq=interval)).last()['FinBertScore'])\n",
    "    \n",
    "    dfgroup = pd.DataFrame(pd.to_datetime(dfgroup.index[:])).join(dfgroup.reset_index(drop=True))\n",
    "    dfgroup = dfgroup.fillna(0)\n",
    "    \n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    res = data.join(dfgroup.set_index(\"date\"), on='timestamp', how='left')\n",
    "    res = res.fillna(0)\n",
    "    res = res.reset_index(drop=True)\n",
    "\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTest(split, stock, dates, profitMult, intervals, algorithms,  steps, \\\n",
    "            units, batchs, profits, epochs, sentiment, relevance, useIndicators, \\\n",
    "            useFinBERT, printFinalData=False, printSplitDataset=False, \\\n",
    "            printModelSummary=False, printLoss=False, printCompare=False, \\\n",
    "            printResult=False, printProfit=False):\n",
    "    \n",
    "    df = None\n",
    "    numberoftests = len(intervals) * len(algorithms) * len(steps) * len(units) *  \\\n",
    "    len(batchs) * len(profits) * len(epochs) * len(sentiment) * len(useIndicators) * len(useFinBERT)\n",
    "    \n",
    "    if True in useFinBERT:\n",
    "        print(\"Calculating FinBERT finantial sentiment predictions...\")\n",
    "        newsdata = getFinBERTdata(stock, dates)\n",
    "        print(\"Finantial sentiment stored in dataset\")\n",
    "    \n",
    "    print ('Running', numberoftests, 'tests:')\n",
    "    \n",
    "    for interval in intervals:\n",
    "        for algorithm in algorithms:\n",
    "            for step in steps:\n",
    "                for unit in units:\n",
    "                    for batch in batchs:\n",
    "                        for epoch in epochs:\n",
    "                            for indicator in useIndicators:\n",
    "                                for sent in sentiment:\n",
    "                                    for finbert in useFinBERT:\n",
    "\n",
    "                                        data = getStockDataFrame(stock, dates )\n",
    "                                        data = groupStocks(data,interval, '')\n",
    "                                        \n",
    "                                        if useIndicators:\n",
    "                                            data = getIndicators(data)\n",
    "                                        else:\n",
    "                                            data = data                        \n",
    "                                        \n",
    "                                        if sent:\n",
    "                                            data = getNewsDataFrame(stock, dates, \\\n",
    "                                                    interval, data, relevance)\n",
    "                                          \n",
    "                                        if finbert:\n",
    "                                            data = getFinbertNewsDataFrame(data, newsdata, interval)\n",
    "                                        data \n",
    "                                        data = data.drop([\"timestamp\"], axis=1)\n",
    "                                        finalData = normalize(data)                            \n",
    "                                     \n",
    "                                        if printFinalData:\n",
    "                                            plotDataset(finalData)\n",
    "                                        print(finalData.shape)\n",
    "                                        train, test = splitData(finalData, split, step)\n",
    "\n",
    "                                        if printSplitDataset:\n",
    "                                            plotSplitDataset(finalData, split)\n",
    "\n",
    "                                        trainX, trainY, testX, testY = dataset2Matrix(train, test, step)\n",
    "                                        model = createModel(algorithm, unit,trainX, step)\n",
    "                                        \n",
    "                                        if printModelSummary:\n",
    "                                            model.summary()\n",
    "                                        \n",
    "                                        trainedModel = trainModel(model,batch,epoch,trainX,trainY)\n",
    "                                        if printLoss:\n",
    "                                            plotLosss(trainedModel)\n",
    "                                        loss = np.sqrt(trainedModel.history.history['loss'][-1])\n",
    "                                        print(testX.shape)                       \n",
    "                                        trainPredict, testPredict = predict(trainedModel,trainX, testX)\n",
    "                                        if printCompare:\n",
    "                                            plotCompare(finalData, testPredict, split)\n",
    "\n",
    "                                        for profit in profits:\n",
    "                                            decision = calculateDecision(test, testPredict, step, profit*profitMult)\n",
    "                                            \n",
    "                                            if printResult:\n",
    "                                                plotResult(finalData, testPredict,split, profit, decision)\n",
    "                                            if printProfit:\n",
    "                                                plotProfit(finalData, split, decision)\n",
    "                                            coincide, nocoincide = calculateProfit(finalData, decision)\n",
    "                                            if coincide+nocoincide == 0:\n",
    "                                                ben = '-'\n",
    "                                            else:\n",
    "                                                ben = str(round(coincide/(coincide+nocoincide)*100,2))+'%'\n",
    "                                            df = pd.concat([df, pd.DataFrame({\n",
    "                                                'Interval': [\"{:>3}\".format(interval)],\n",
    "                                                'Algorithm': [\"{:>5}\".format(algorithm)],\n",
    "                                                'Steps':[\"{:3}\".format(step)],\n",
    "                                                'Units':[\"{:4}\".format(unit)],\n",
    "                                                'Batchs':[\"{:5}\".format(batch)],\n",
    "                                                'Epochs':[\"{:3}\".format(epoch)],\n",
    "                                                'ExpectedProfit':[\"{:11.8f}\".format(profit*profitMult)],\n",
    "                                                'RMSELoss': [\"{:9.6f}\".format(loss)],\n",
    "                                                'Indicators' : [\"{:>6}\".format(str(indicator))],\n",
    "                                                'CalculatedSentiment' : [\"{:>6}\".format(str(sent))],\n",
    "                                                'FinBERTSentiment' : [\"{:>6}\".format(str(finbert))],\n",
    "                                                'Relevance' : [\"{:>4}\".format(relevance)],\n",
    "                                                'GoodPrediction': [\"{:4}\".format(coincide)],\n",
    "                                                'BadPrediction': [\"{:4}\".format(nocoincide)],\n",
    "                                                'Accuracy': [\"{:>7}\".format(ben)]                                    \n",
    "                                            })])\n",
    "\n",
    "                                            print(df.iloc[-1:].to_string(header=False, index=False))\n",
    "                                            \n",
    "                                            #Export dataset to CSV\n",
    "                                            df.to_csv('Datasets/Tests_Results-' + stock + str(dates)+ \\\n",
    "                                                'Interval-' + str(intervals) + str(algorithms) + 'Steps-' + \\\n",
    "                                                str(steps) + 'Units-' + str(units) + 'Batchs-' + str(batchs)+ \\\n",
    "                                                'Epochs-' + str(epochs) + 'profitMult-' + str(profitMult) + \\\n",
    "                                                'Sentiment-' + str(sentiment) + 'FinBERT-' + str(useFinBERT) + \\\n",
    "                                                'Indicators' + str(useIndicators) + '.csv', index=False)                                \n",
    "    df.reset_index(drop=True)\n",
    "    print(\"Tests finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FinBERT finantial sentiment predictions...\n",
      "Finantial sentiment stored in dataset\n",
      "Running 1440 tests:\n",
      "(998, 12)\n",
      "(300, 10, 12)\n",
      "12h  LSTM  10  100    16   5  0.00000010  0.066171   True   True   True  7.0  174  125  58.19%\n",
      "12h  LSTM  10  100    16   5  0.00000100  0.066171   True   True   True  7.0  174  125  58.19%\n",
      "12h  LSTM  10  100    16   5  0.00001000  0.066171   True   True   True  7.0  174  124  58.39%\n",
      "12h  LSTM  10  100    16   5  0.00010000  0.066171   True   True   True  7.0  174  122  58.78%\n",
      "12h  LSTM  10  100    16   5  0.00100000  0.066171   True   True   True  7.0  156  115  57.56%\n",
      "(998, 11)\n",
      "(300, 10, 11)\n",
      "12h  LSTM  10  100    16   5  0.00000010  0.064664   True   True  False  7.0  176  123  58.86%\n",
      "12h  LSTM  10  100    16   5  0.00000100  0.064664   True   True  False  7.0  176  123  58.86%\n",
      "12h  LSTM  10  100    16   5  0.00001000  0.064664   True   True  False  7.0  176  122  59.06%\n",
      "12h  LSTM  10  100    16   5  0.00010000  0.064664   True   True  False  7.0  176  120  59.46%\n",
      "12h  LSTM  10  100    16   5  0.00100000  0.064664   True   True  False  7.0  156  119  56.73%\n",
      "(998, 10)\n",
      "(300, 10, 10)\n",
      "12h  LSTM  10  100    16   5  0.00000010  0.064622   True  False   True  7.0  176  123  58.86%\n",
      "12h  LSTM  10  100    16   5  0.00000100  0.064622   True  False   True  7.0  176  123  58.86%\n",
      "12h  LSTM  10  100    16   5  0.00001000  0.064622   True  False   True  7.0  176  123  58.86%\n",
      "12h  LSTM  10  100    16   5  0.00010000  0.064622   True  False   True  7.0  176  120  59.46%\n",
      "12h  LSTM  10  100    16   5  0.00100000  0.064622   True  False   True  7.0  158  116  57.66%\n",
      "(998, 9)\n",
      "(300, 10, 9)\n",
      "12h  LSTM  10  100    16   5  0.00000010  0.062458   True  False  False  7.0  171  128  57.19%\n",
      "12h  LSTM  10  100    16   5  0.00000100  0.062458   True  False  False  7.0  171  128  57.19%\n",
      "12h  LSTM  10  100    16   5  0.00001000  0.062458   True  False  False  7.0  171  128  57.19%\n",
      "12h  LSTM  10  100    16   5  0.00010000  0.062458   True  False  False  7.0  170  124  57.82%\n",
      "12h  LSTM  10  100    16   5  0.00100000  0.062458   True  False  False  7.0  150  116  56.39%\n",
      "(998, 12)\n",
      "(300, 10, 12)\n",
      "12h  LSTM  10  100    16   5  0.00000010  0.065466  False   True   True  7.0  170  129  56.86%\n",
      "12h  LSTM  10  100    16   5  0.00000100  0.065466  False   True   True  7.0  170  129  56.86%\n",
      "12h  LSTM  10  100    16   5  0.00001000  0.065466  False   True   True  7.0  170  129  56.86%\n",
      "12h  LSTM  10  100    16   5  0.00010000  0.065466  False   True   True  7.0  166  128  56.46%\n",
      "12h  LSTM  10  100    16   5  0.00100000  0.065466  False   True   True  7.0  153  118  56.46%\n",
      "(998, 11)\n",
      "(300, 10, 11)\n",
      "12h  LSTM  10  100    16   5  0.00000010  0.059952  False   True  False  7.0  178  121  59.53%\n",
      "12h  LSTM  10  100    16   5  0.00000100  0.059952  False   True  False  7.0  178  121  59.53%\n",
      "12h  LSTM  10  100    16   5  0.00001000  0.059952  False   True  False  7.0  178  121  59.53%\n",
      "12h  LSTM  10  100    16   5  0.00010000  0.059952  False   True  False  7.0  177  121   59.4%\n",
      "12h  LSTM  10  100    16   5  0.00100000  0.059952  False   True  False  7.0  152  118   56.3%\n",
      "(998, 10)\n",
      "(300, 10, 10)\n",
      "12h  LSTM  10  100    16   5  0.00000010  0.065553  False  False   True  7.0  171  128  57.19%\n",
      "12h  LSTM  10  100    16   5  0.00000100  0.065553  False  False   True  7.0  171  128  57.19%\n",
      "12h  LSTM  10  100    16   5  0.00001000  0.065553  False  False   True  7.0  171  128  57.19%\n",
      "12h  LSTM  10  100    16   5  0.00010000  0.065553  False  False   True  7.0  170  128  57.05%\n",
      "12h  LSTM  10  100    16   5  0.00100000  0.065553  False  False   True  7.0  150  115   56.6%\n",
      "(998, 9)\n",
      "(300, 10, 9)\n",
      "12h  LSTM  10  100    16   5  0.00000010  0.060458  False  False  False  7.0  175  124  58.53%\n",
      "12h  LSTM  10  100    16   5  0.00000100  0.060458  False  False  False  7.0  175  124  58.53%\n",
      "12h  LSTM  10  100    16   5  0.00001000  0.060458  False  False  False  7.0  175  124  58.53%\n",
      "12h  LSTM  10  100    16   5  0.00010000  0.060458  False  False  False  7.0  173  124  58.25%\n",
      "12h  LSTM  10  100    16   5  0.00100000  0.060458  False  False  False  7.0  157  120  56.68%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrunTest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAAPL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2022\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#['2022','2023']\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprofitMult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.000001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintervals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m12h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#['1min', '10min', '60min', '6h', '12h', '1D']\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m#['RNN', 'LSTM']\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m#[2, 5, 10, 20]\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43munits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m#[50, 100., 150]\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatchs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m#[16,64,128]\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprofits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m#[1,10,100,1000]\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m#[5, 10, 20]\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msentiment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#[True, False]\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43museFinBERT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m#[True, False]\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelevance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# 0.0-1.0\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43museIndicators\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#[True, False]\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintFinalData\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintSplitDataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintModelSummary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintLoss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintCompare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintResult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintProfit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#Arreglar títulos de los gráficos\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[134], line 28\u001b[0m, in \u001b[0;36mrunTest\u001b[1;34m(split, stock, dates, profitMult, intervals, algorithms, steps, units, batchs, profits, epochs, sentiment, relevance, useIndicators, useFinBERT, printFinalData, printSplitDataset, printModelSummary, printLoss, printCompare, printResult, printProfit)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentiment:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m finbert \u001b[38;5;129;01min\u001b[39;00m useFinBERT:\n\u001b[1;32m---> 28\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mgetStockDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m         data \u001b[38;5;241m=\u001b[39m groupStocks(data,interval, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m useIndicators:\n",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m, in \u001b[0;36mgetStockDataFrame\u001b[1;34m(stock, years)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m YEARS:\n\u001b[0;32m      9\u001b[0m     FILE\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/Stock-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mSTOCK\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39myear\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 10\u001b[0m     ds\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     file \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([file,ds])\n\u001b[0;32m     12\u001b[0m file \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runTest(\n",
    "    split = 0.7, \n",
    "    stock ='AAPL', \n",
    "    dates = ['2022','2023'],        #['2022','2023']\n",
    "    profitMult = 0.000001,\n",
    "    intervals = ['12h'],            #['1min', '10min', '60min', '6h', '12h', '1D']\n",
    "    algorithms = ['LSTM'],          #['RNN', 'LSTM']\n",
    "    steps = [10, 20],               #[2, 5, 10, 20]\n",
    "    units = [100,150,200],                  #[50, 100., 150]\n",
    "    batchs = [16,64,128],           #[16,64,128]\n",
    "    profits = [0.1,1,10,100,1000] ,     #[1,10,100,1000]\n",
    "    epochs = [5, 10],               #[5, 10, 20]\n",
    "    sentiment = [True, False],            #[True, False]\n",
    "    useFinBERT =[True, False],             #[True, False]\n",
    "    relevance = 7.0,                # 0.0-1.0\n",
    "    useIndicators = [True, False],  #[True, False]\n",
    "    printFinalData=False, \n",
    "    printSplitDataset=False, \n",
    "    printModelSummary=False, \n",
    "    printLoss=False, \n",
    "    printCompare=False, \n",
    "    printResult=False, \n",
    "    printProfit=False\n",
    "    ) \n",
    "#Arreglar títulos de los gráficos\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
