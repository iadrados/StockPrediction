{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZlLIu7uE5ma"
   },
   "source": [
    "# Stock Prediction\n",
    "### Ignacio Fernández Adrados\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%pip install pandas\\n%pip install scikit-learn\\n%pip install matplotlib\\n%pip install numpy\\n%pip install keras\\n%pip install tensorflow\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install keras\n",
    "%pip install tensorflow\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "seE3JuEGE5mh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # type: ignore\n",
    "\n",
    "def getStockDataFrame (stock, years):\n",
    "    STOCK = stock\n",
    "    YEARS = years\n",
    "\n",
    "    file = None\n",
    "    for year in YEARS:\n",
    "        FILE='Datasets/Stock-'+STOCK+'-'+year+'.csv'\n",
    "        ds=pd.read_csv(FILE, sep=',')\n",
    "        file = pd.concat([file,ds])\n",
    "    file = file.sort_values(by='timestamp', ascending=True)\n",
    "    return file\n",
    "#getStockDataFrame('AAPL', ['2022','2023'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX9Mv-nZFlXk",
    "outputId": "2a025661-a286-4991-9260-66628ec2a250"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def groupStocks(dataset, n, datefilter):\n",
    "\n",
    "    N=n     #Minutos agrupados\n",
    "    DATEFILTER=datefilter #Filtro de fecha\n",
    "    file = dataset\n",
    "    \n",
    "    df = file[file['timestamp'].str.startswith(DATEFILTER)]\n",
    "    df=pd.DataFrame(df)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    dfgroup = pd.DataFrame(df.groupby(pd.Grouper(key='timestamp', freq=N)).first()['open'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).last()['close'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).min()['low'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).max()['high'])\n",
    "    dfgroup = dfgroup.join(df.groupby(pd.Grouper(key='timestamp', freq=N)).sum()['volume'])\n",
    "    #dfgroup = dfgroup[:-1].reset_index(drop=True)\n",
    "    dfgroup = pd.DataFrame(pd.to_datetime(dfgroup.index[:])).join(dfgroup.reset_index(drop=True))\n",
    "    dfgroup = dfgroup.dropna().reset_index(drop=True)\n",
    "    return dfgroup\n",
    "#xxx = groupStocks(getStockDataFrame('AAPL', ['2022']), '1D', '')\n",
    "#xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "z2bs-Qemi12t",
    "outputId": "161bc113-e1f6-4b25-d8d9-b56f9f078f66"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_rsi(close, lookback):\n",
    "    ret = close.diff()\n",
    "    up = []\n",
    "    down = []\n",
    "    for i in range(len(ret)):\n",
    "        if ret[i] < 0:\n",
    "            up.append(0)\n",
    "            down.append(ret[i])\n",
    "        else:\n",
    "            up.append(ret[i])\n",
    "            down.append(0)\n",
    "    up_series = pd.Series(up)\n",
    "    down_series = pd.Series(down).abs()\n",
    "    up_ewm = up_series.ewm(com = lookback - 1, adjust = False).mean()\n",
    "    down_ewm = down_series.ewm(com = lookback - 1, adjust = False).mean()\n",
    "    rs = up_ewm/down_ewm\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    rsi_df = pd.DataFrame(rsi).rename(columns = {0:'rsi'}).set_index(close.index)\n",
    "    rsi_df = rsi_df.dropna()\n",
    "    return rsi_df[3:]\n",
    "\n",
    "def getIndicators(dataset):\n",
    "    \n",
    "    dfgroup = dataset\n",
    "\n",
    "    dfgroup['EMA7']= dfgroup['close'].ewm(span=7, adjust=False).mean()\n",
    "    dfgroup['MACD']= dfgroup['close'].ewm(span=12, adjust=False).mean()- dfgroup['close'].ewm(span=26, adjust=False).mean()\n",
    "    dfgroup['SignalMACD'] = dfgroup['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    dfgroup['RSI'] = get_rsi(dfgroup['close'], 14)\n",
    "    dfgroup = dfgroup.dropna()\n",
    "    dfgroup = dfgroup.reset_index(drop=True)\n",
    "    return dfgroup\n",
    "\n",
    "#getIndicators(xxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadiendo sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewsDataFrame(stock, date, interval, stockDataFrame, relevance):\n",
    "    STOCK = stock\n",
    "    YEARS = date\n",
    "    file = None\n",
    "    for year in YEARS:\n",
    "        FILE='Datasets/News-'+STOCK+'-'+year+'.csv'\n",
    "        ds=pd.read_csv(FILE, sep=',')\n",
    "        file = pd.concat([file,ds])\n",
    "    file = file.sort_values(by='date', ascending=True)\n",
    "    file['date'] = pd.to_datetime(file['date'], format='%Y%m%dT%H%M%S')\n",
    "    file = file.drop(['title','summary','ticker'], axis=1)\n",
    "    file = file[file['relevance']>=relevance]\n",
    "\n",
    "    dfgroup = pd.DataFrame(file.groupby(pd.Grouper(key='date', freq=interval)).last()['relevance'])\n",
    "    dfgroup = dfgroup.join(file.groupby(pd.Grouper(key='date', freq=interval)).last()['sentiment'])\n",
    "    dfgroup = pd.DataFrame(pd.to_datetime(dfgroup.index[:])).join(dfgroup.reset_index(drop=True))\n",
    "    dfgroup = dfgroup.fillna(0)\n",
    "    stockDataFrame['timestamp'] = pd.to_datetime(stockDataFrame['timestamp'])\n",
    "    res = stockDataFrame.join(dfgroup.set_index(\"date\"), on='timestamp', how='left')\n",
    "    res = res.fillna(0)\n",
    "    res = res.reset_index(drop=True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TBisHNoeE5mo",
    "outputId": "314904d0-9fde-4c6f-96fd-1eaaff6387dc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize(dataset):\n",
    "    #Normalise data into (0,1) range\n",
    "    normData=dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    #normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']] = \\\n",
    "    #    scaler.fit_transform(normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']])\n",
    "    #print(normData[['open','close','low','high','volume','EMA7','MACD','SignalMACD','RSI']].head(1))\n",
    "    c=normData.columns.values\n",
    "    normData[c] = scaler.fit_transform(normData[c])\n",
    "    return normData\n",
    "\n",
    "##################################################3\n",
    "#data = getStockDataFrame('AAPL', ['2023'])\n",
    "#indicatorData = groupStocks(data, '1D', '')\n",
    "#indicatorData = getNewsDataFrame('AAPL', ['2023'], '1D', indicatorData, 0)\n",
    "#indicatorData = indicatorData.drop(['timestamp'], axis=1)\n",
    "#normalize(indicatorData)\n",
    "##################################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "hY9NX9AeE5mp",
    "outputId": "6d446865-54a0-4bb4-b540-46dc88bb3e9d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotDataset(dataset):\n",
    "\n",
    "    normData = dataset\n",
    "    \n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Dataset 'Close' data \")\n",
    "    plt.plot(normData['close'],color='black')\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] == -1,normData['close'], None), color=\"red\", marker=\"v\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] ==  1,normData['close'], None), color=\"blue\", marker=\"^\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W41DlLEoE5mq"
   },
   "source": [
    "### Split the values in train and test\n",
    "\n",
    "So, we took only 25% of the data as training samples and set aside the rest of the data for testing.\n",
    "\n",
    "Looking at the time-series plot, we think **it is not easy for a standard model to come up with correct trend predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "es2T4CuCE5mr",
    "outputId": "7e2cbeb1-c779-415b-ba2d-295f95a7a854"
   },
   "outputs": [],
   "source": [
    "def splitData(dataset, split, step):\n",
    "\n",
    "    S=split\n",
    "    step = step\n",
    "    normData = dataset\n",
    "\n",
    "    split = int(len(normData) * S)\n",
    "    #values = normData.values\n",
    "    #print(values)\n",
    "    train = normData[:split]#.drop(['buysell'],axis=1)\n",
    "    test = pd.concat([train.tail(step),normData[split:]]).reset_index(drop=True)\n",
    "\n",
    "    #print(\"Train data length:\", train.shape)\n",
    "    #print(\"Test data length:\", test.shape)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "yq8Pr6juE5ms",
    "outputId": "0870926c-f065-418c-e5bd-07c141e27bce"
   },
   "outputs": [],
   "source": [
    "def plotSplitDataset(dataset, split):\n",
    "    \n",
    "    normData = dataset\n",
    "    split = int(len(normData) * split)\n",
    "\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Dataset 'Close' data split\")\n",
    "    plt.plot(normData.index.values,normData['close'],c='black')\n",
    "    plt.axvline(normData.index[split], c=\"r\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] == -1,normData['close'], None), color=\"red\",  marker=\"v\")\n",
    "    #plt.scatter(normData.index, np.where(normData['buysell'] ==  1,normData['close'], None), color=\"blue\", marker=\"^\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4No4lvOSE5mu"
   },
   "source": [
    "### Converting to a multi-dimensional array\n",
    "Next, we'll convert test and train data into the matrix with step value as it has shown above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8J-93wpyE5mu",
    "outputId": "1deefe1b-450d-4a34-98c4-c526e71c4688"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convertToMatrix(data, step):\n",
    "    X, Y =[], []\n",
    "    for i in range(len(data)-step):\n",
    "        d=i+step\n",
    "        #print(i, d, data[i:d)\n",
    "        X.append(data[i:d])\n",
    "        Y.append(data[d,1])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def dataset2Matrix(train, test, step):\n",
    "    trainX,trainY =convertToMatrix(train.to_numpy(),step)\n",
    "    testX,testY =convertToMatrix(test.to_numpy(),step)\n",
    "    #print(trainY)\n",
    "    #print(\"Training data shape:\", trainX.shape,', ',trainY.shape)\n",
    "    #print(\"Test data shape:\", testX.shape,', ',testY.shape)\n",
    "    return trainX, trainY, testX, testY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfLqFjJxE5mw"
   },
   "source": [
    "### Keras model with `SimpleRNN` layer\n",
    "\n",
    "- 256 neurons in the RNN layer\n",
    "- 32 denurons in the densely connected layer\n",
    "- a single neuron for the output layer\n",
    "- ReLu activation\n",
    "- learning rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "4BjedTvlE5mw",
    "outputId": "a224d1e0-e032-4e1b-d276-12049d88cebb"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, LSTM, Dropout # type: ignore\n",
    "\n",
    "def createModel(type, units, trainX, step):\n",
    "    UNITS = units #num_units: Number of units of a the simple RNN layer\n",
    "    DENSEUNITS = 32 #Number of neurons in the dense layer followed by the RNN layer\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input((step, trainX.shape[2])))\n",
    "    if type==\"LSTM\":\n",
    "        model.add(LSTM(units=UNITS, activation=\"tanh\",return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=UNITS//2, activation=\"tanh\"))\n",
    "        model.add(Dropout(0.2))      \n",
    "    elif type == \"RNN\":\n",
    "        model.add(SimpleRNN(units=UNITS, activation=\"relu\",return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(SimpleRNN(units=UNITS//2, activation=\"relu\"))\n",
    "        model.add(Dropout(0.2))     \n",
    "    model.add(Dense(DENSEUNITS, activation=\"tanh\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mse'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg4jkMzRE5mz"
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyGK1fyFE5mz",
    "outputId": "9a183877-c6d8-4587-802c-12e4f8c4e138"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback # type: ignore\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        #if (epoch+1) % 10 == 0 and epoch>0:\n",
    "            print(\"Epoch number {} done\".format(epoch+1))\n",
    "\n",
    "def trainModel(model, batch, epochs, trainX, trainY):\n",
    "    batch_size=batch\n",
    "    num_epochs = epochs\n",
    "\n",
    "    model.fit(trainX,trainY,\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=None,verbose=0\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8u8PJjdE5m0"
   },
   "source": [
    "### Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "UoYGhk7EE5m0",
    "outputId": "4f2b1a4c-31cc-4eab-e5d0-f86b9c6489bd"
   },
   "outputs": [],
   "source": [
    "def plotLosss(model):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.title(\"RMSE loss over epochs\",fontsize=16)\n",
    "    plt.plot(np.sqrt(model.history.history['loss']),c='k',lw=2)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Epochs\",fontsize=14)\n",
    "    plt.ylabel(\"Root-mean-squared error\",fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d_0G0OpE5m1"
   },
   "source": [
    "### Predictions\n",
    "Note that the model was fitted only with the `trainX` and `trainY` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-cH3SZuE5m2",
    "outputId": "56231db1-6f88-4b7e-8352-aaa6520a042e"
   },
   "outputs": [],
   "source": [
    "def predict(model, trainX, testX):\n",
    "    trainPredict = model.predict(trainX, verbose=0)\n",
    "    testPredict= model.predict(testX, verbose=0)\n",
    " \n",
    "    predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "    #print(trainPredict.shape)\n",
    "    #print(testPredict.shape)\n",
    "\n",
    "    return trainPredict, testPredict, predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enWdLcInE5m3"
   },
   "source": [
    "### Comparing it with the ground truth (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "MoxCTnZqE5m3",
    "outputId": "32af9acf-1724-414b-e43f-8f5b0ce90759"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plotCompare(normData, testPredict, split):\n",
    "\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "    #index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black', label='Ground Truth')\n",
    "    plt.plot(testPredict[OFFSET:],color='blue', label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDecision(test, testPredict, step, profit):\n",
    "\n",
    "    PROFIT = profit\n",
    "\n",
    "    decision=test['close'].iloc[step:]\n",
    "    decision = decision.diff()\n",
    "    decision = decision.dropna()\n",
    "    decision = np.where(abs(decision)<PROFIT,0,np.sign(decision).astype('int'))\n",
    "    decision = pd.DataFrame(data={'buysell':decision})#.drop(0).reset_index(drop=True)\n",
    "\n",
    "    predictedDecision = pd.DataFrame(data={'buysellPredicted':testPredict[:,0]})\n",
    "    predictedDecision = predictedDecision.diff()\n",
    "    predictedDecision = predictedDecision.dropna()#.reset_index(drop=True)\n",
    "    predictedDecision = np.where(abs(predictedDecision)<PROFIT,0,np.sign(predictedDecision).astype('int'))\n",
    "    predictedDecision = pd.DataFrame(data={'buysellPredicted':predictedDecision[:,0]})\n",
    "\n",
    "    decision = decision.join(predictedDecision)\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "Xg5ICE2T8JSa",
    "outputId": "5c4d5a98-1cf4-4899-ca4a-c1cd85f97b4e"
   },
   "outputs": [],
   "source": [
    "def plotResult(normData, testPredict, split, profit, decision):\n",
    "\n",
    "    PROFIT=profit\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "\n",
    "    \n",
    "\n",
    "    index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black')\n",
    "    plt.plot(testPredict[OFFSET:],color='blue')\n",
    "\n",
    "    x = decision.iloc[OFFSET:].reset_index(drop=True).index\n",
    "    y = normData['close'].iloc[len(normData)-len(decision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "\n",
    "    plt.scatter(x, np.where(decision['buysell'].iloc[OFFSET:] == -1,y, None), color=\"red\",  marker=\"v\", label='Ground Truth Sell')\n",
    "    plt.scatter(x, np.where(decision['buysell'].iloc[OFFSET:] ==  1,y, None), color=\"blue\", marker=\"^\", label='Ground Truth Buy')\n",
    "\n",
    "    plt.scatter(x, np.where(decision['buysellPredicted'].iloc[OFFSET:] == -1,y-0.015, None), color=\"orange\",  marker=\"v\", label='Prediction Sell')\n",
    "    plt.scatter(x, np.where(decision['buysellPredicted'].iloc[OFFSET:] ==  1,y+0.015, None), color=\"green\",  marker=\"^\", label='Prediction Buy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "K8VIy1uYFhdb",
    "outputId": "66fae12b-291b-4cce-a052-b57ee39fd236"
   },
   "outputs": [],
   "source": [
    "def plotProfit(normData, split, decision):\n",
    "\n",
    "    OFFSET=0\n",
    "    split = int(len(normData) * split)\n",
    "    index = normData.index.values\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.title(\"Ground truth and prediction together\",fontsize=18)\n",
    "    plt.plot(normData['close'].iloc[split+OFFSET:].reset_index(drop=True),color='black')\n",
    "    #plt.plot(testPredict[OFFSET:],color='blue')\n",
    "\n",
    "    x = decision.iloc[OFFSET:].reset_index(drop=True).index\n",
    "    y = normData['close'].iloc[len(normData)-len(decision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "\n",
    "    plt.scatter(x, np.where((decision['buysell'].iloc[OFFSET:] !=  decision['buysellPredicted'].iloc[OFFSET:]) & (decision['buysellPredicted'].iloc[OFFSET:] != 0),y, None), color=\"red\", label='Ground Truth Buy')\n",
    "    plt.scatter(x, np.where((decision['buysell'].iloc[OFFSET:] == decision['buysellPredicted'].iloc[OFFSET:]) & (decision['buysell'].iloc[OFFSET:] != 0),y, None), color=\"green\",  label='Ground Truth Sell')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yN3Hp3azZi3c",
    "outputId": "1a0bbe4e-1fc8-413a-cd3c-aa7b277e5c31"
   },
   "outputs": [],
   "source": [
    "def calculateProfit(normData, decision):\n",
    "\n",
    "    OFFSET=0\n",
    "    y = normData['close'].iloc[len(normData)-len(decision.index)-1+OFFSET:-1].reset_index(drop=True)\n",
    "    \n",
    "    #print(\"Predicciones no coincidentes con el conjunto de pruebas: \", \\\n",
    "    nocoincide =np.count_nonzero(np.where((decision['buysell'].iloc[OFFSET:] !=  decision['buysellPredicted'].iloc[OFFSET:]) \\\n",
    "          & (decision['buysellPredicted'].iloc[OFFSET:] != 0),y, None))#)\n",
    "    #print(\"Predicciones coincidentes con el conjunto de pruebas: \", \\\n",
    "    coincide=np.count_nonzero(np.where((decision['buysell'].iloc[OFFSET:] == decision['buysellPredicted'].iloc[OFFSET:]) \\\n",
    "          & (decision['buysell'].iloc[OFFSET:] != 0),y, None))#)\n",
    "    return coincide, nocoincide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTest(split, stock, dates, profitMult, intervals, algorithms, steps, units, batchs, profits, epochs, sentiment, relevance, useIndicators):\n",
    "    df = None\n",
    "    i=0\n",
    "    for interval in intervals:\n",
    "        for algorithm in algorithms:\n",
    "            for step in steps:\n",
    "                for unit in units:\n",
    "                    for batch in batchs:\n",
    "                        for epoch in epochs:\n",
    "                            for indicator in useIndicators:\n",
    "                                for sent in sentiment:\n",
    "                                    #print('Calculating iteration:', i, ':', 'interval:', str(interval) + \",\",\n",
    "                                    #    'algorithm:', algorithm + \",\", 'step:', str(step) + \",\", 'unit:', str(unit), 'batch:', str(batch) + \",\",\n",
    "                                    #    'profit:', str(profit*profitMult) + \",\", 'epoch:', str(epoch))\n",
    "                                    i += 1\n",
    "                                    data = getStockDataFrame(stock, dates )\n",
    "                                    groupedData = groupStocks(data,interval, '')#.drop(['timestamp'],axis=1)\n",
    "                                    if useIndicators:\n",
    "                                        indicatorData = getIndicators(groupedData)\n",
    "                                    else:\n",
    "                                        indicatorData = groupedData                        \n",
    "                                    \n",
    "                                    if sentiment:\n",
    "                                        indicatorData = getNewsDataFrame(stock, dates, interval, indicatorData, relevance)\n",
    "                                    indicatorData = indicatorData.drop([\"timestamp\"], axis=1)\n",
    "                                    finalData = normalize(indicatorData)                            \n",
    "                                    #print(finalData)\n",
    "                                    #plotDataset(finalData)\n",
    "                                    train, test = splitData(finalData, split, step)\n",
    "                                    #plotSplitDataset(s4, split)\n",
    "                                    trainX, trainY, testX, testY = dataset2Matrix(train, test, step)\n",
    "                                    model = createModel(algorithm, unit,trainX, step)\n",
    "                                    #model.summary()\n",
    "                                    trainedModel = trainModel(model,batch,epoch,trainX,trainY)\n",
    "                                    #plotLosss(trainedModel)\n",
    "                                    loss = np.sqrt(trainedModel.history.history['loss'][-1])\n",
    "                                    #print ('RMSE loss :', loss)\n",
    "                                    trainPredict, testPredict, predicted = predict(trainedModel,trainX, testX)\n",
    "                                    #plotCompare(finalData, testPredict, split)\n",
    "\n",
    "                                    for profit in profits:\n",
    "                                        decision = calculateDecision(test, testPredict, step, profit*profitMult)\n",
    "\n",
    "                                        #plotResult(finalData, testPredict,split, profit, decision)\n",
    "                                        #plotProfit(finalData, split, decision)\n",
    "                                        coincide, nocoincide = calculateProfit(finalData, decision)\n",
    "                                        if coincide+nocoincide == 0:\n",
    "                                            ben = '-'\n",
    "                                        else:\n",
    "                                            ben = str(round(coincide/(coincide+nocoincide)*100,2))+'%'\n",
    "                                        df = pd.concat([df, pd.DataFrame({\n",
    "                                            'int': [\"{:>3}\".format(interval)],\n",
    "                                            'algo': [\"{:>5}\".format(algorithm)],\n",
    "                                            'step':[\"{:3}\".format(step)],\n",
    "                                            'unit':[\"{:4}\".format(unit)],\n",
    "                                            'bat':[\"{:5}\".format(batch)],\n",
    "                                            'epo':[\"{:3}\".format(epoch)],\n",
    "                                            'profit':[\"{:9.6f}\".format(profit*profitMult)],\n",
    "                                            'loss': [\"{:9.6f}\".format(loss)],\n",
    "                                            'indicators:' : [\"{:>6}\".format(str(indicator))],\n",
    "                                            'sentiment' : [\"{:>6}\".format(str(sent))],\n",
    "                                            'relevance' : [\"{:>4}\".format(relevance)],\n",
    "                                            'good': [\"{:4}\".format(coincide)],\n",
    "                                            'bad': [\"{:4}\".format(nocoincide)],\n",
    "                                            'benefit': [\"{:>7}\".format(ben)]                                    \n",
    "                                        })])\n",
    "\n",
    "                                        print(df.iloc[-1:].to_string(header=False, index=False))\n",
    "                                        df.to_csv('Datasets/Tests_Results-'+stock + str(dates)+ \\\n",
    "                                            str(intervals)+str(algorithms)+str(steps)+str(units)+str(batchs)+ \\\n",
    "                                            str(epochs)+str(profitMult)+str(sentiment)+str(useIndicators)+'.csv', index=False)\n",
    "\n",
    "                              \n",
    "    df.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando 48 tests:\n",
      "12h  LSTM  10  100    16   5  0.000000  0.068164   True   True  0.8  173  126  57.86%\n",
      "12h  LSTM  10  100    16   5  0.000000  0.064848   True  False  0.8  183  116   61.2%\n",
      "12h  LSTM  10  100    16   5  0.000000  0.063458  False   True  0.8  170  129  56.86%\n",
      "12h  LSTM  10  100    16   5  0.000000  0.066876  False  False  0.8  175  124  58.53%\n",
      "12h  LSTM  10  100    16  10  0.000000  0.063470   True   True  0.8  181  118  60.54%\n",
      "12h  LSTM  10  100    16  10  0.000000  0.057191   True  False  0.8  175  124  58.53%\n",
      "12h  LSTM  10  100    16  10  0.000000  0.057954  False   True  0.8  176  123  58.86%\n",
      "12h  LSTM  10  100    16  10  0.000000  0.055583  False  False  0.8  176  123  58.86%\n",
      "12h  LSTM  10  100    64   5  0.000000  0.075478   True   True  0.8  169  130  56.52%\n",
      "12h  LSTM  10  100    64   5  0.000000  0.074481   True  False  0.8  180  119   60.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m numberoftests \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(intervals)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(algorithms)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(steps)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(units)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(batchs)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(profits)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(epochs)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(sentiment)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(useIndicators)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEjecutando\u001b[39m\u001b[38;5;124m'\u001b[39m, numberoftests, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtests:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mrunTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprofitMult\u001b[49m\u001b[43m,\u001b[49m\u001b[43mintervals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43museIndicators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEjecución finalizada\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 34\u001b[0m, in \u001b[0;36mrunTest\u001b[1;34m(split, stock, dates, profitMult, intervals, algorithms, steps, units, batchs, profits, epochs, sentiment, relevance, useIndicators)\u001b[0m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m createModel(algorithm, unit,trainX, step)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#model.summary()\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m trainedModel \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#plotLosss(trainedModel)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(trainedModel\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(model, batch, epochs, trainX, trainY)\u001b[0m\n\u001b[0;32m      9\u001b[0m batch_size\u001b[38;5;241m=\u001b[39mbatch\n\u001b[0;32m     10\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m epochs\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    915\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[0;32m    916\u001b[0m           bound_args\n\u001b[0;32m    917\u001b[0m       )\n\u001b[0;32m    918\u001b[0m   )\n\u001b[1;32m--> 919\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    920\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[0;32m    925\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\iadra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "split = 0.7\n",
    "stock = 'AAPL'\n",
    "dates = ['2022','2023']\n",
    "profitMult=0.000001\n",
    "\n",
    "intervals = ['12h']         #['1min', '10min', '60min', '6h', '12h', '1D']\n",
    "algorithms = ['LSTM']       #['RNN', 'LSTM']\n",
    "steps   = [10, 20]          #[2, 5, 10, 20]\n",
    "units   = [100]             #[50, 100., 150]\n",
    "batchs  = [16,64,128]       #[16,64,128]\n",
    "epochs  = [5, 10]           #[5, 10, 20]\n",
    "profits = [1,10,100,1000]   #[1,10,100,1000]\n",
    "sentiment = [True, False]   #[True, False]\n",
    "relevance = 0.8             # 0.0-1.0\n",
    "useIndicators=[True, False] #[True, False]\n",
    "\n",
    "numberoftests = len(intervals)*len(algorithms)*len(steps)*len(units)*len(batchs)*len(profits)*len(epochs)*len(sentiment)*len(useIndicators)\n",
    "print ('Ejecutando', numberoftests, 'tests:')\n",
    "\n",
    "runTest(split, stock, dates,profitMult,intervals, algorithms, steps, units, batchs, profits, epochs, sentiment, relevance, useIndicators)\n",
    "print(\"Ejecución finalizada\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
